{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aFdhLBpZFjr"
      },
      "source": [
        "### Convolutional Neural Network (CNN) for Processing and Classifying CIFAR-10 Images from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1: Initial Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "hau8Ji04ZDa9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "np.random.seed(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load up initial data from CIFAR-10:\n",
        "* 10 classes of images (airplane, automobile, bird...)\n",
        "* 6000 images per class (5000 train, 1000 test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(31.5), np.float64(31.5), np.float64(-0.5))"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def load_batch_from_file(file_path):\n",
        "    # load data from a CIFAR-10 batch file using pickle\n",
        "    with open(file_path, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='bytes')\n",
        "    data = np.array(batch[b'data'])\n",
        "    labels = np.array(batch[b'labels'])\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "# reshape data into 3 channels of 32x32 images\n",
        "data, labels = load_batch_from_file('cifar-10-batches-py/data_batch_1')\n",
        "data_separated = data[0].reshape(3, 32, 32)\n",
        "\n",
        "img = data_separated.transpose(1, 2, 0)  # (H, W, C)\n",
        "\n",
        "# display first image for test\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process all training and test batches from cifar-10-batches-py folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (50000, 3072)\n",
            "Y_train: (50000,)\n",
            "X_test: (10000, 3072)\n",
            "Y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "def load_batches():\n",
        "    X_list, Y_list = [], []\n",
        "\n",
        "    # load training batches 1 to 5\n",
        "    for i in range(1, 6):\n",
        "        path = f'cifar-10-batches-py/data_batch_{i}'\n",
        "        data, labels = load_batch_from_file(path)\n",
        "\n",
        "        X_list.append(data)\n",
        "        Y_list.append(labels)\n",
        "\n",
        "    # concatenate all training batches\n",
        "    X_train = np.concatenate(X_list)\n",
        "    Y_train = np.concatenate(Y_list)\n",
        "\n",
        "    # test batch\n",
        "    X_test, Y_test = load_batch_from_file('cifar-10-batches-py/test_batch')\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = load_batches()\n",
        "\n",
        "# shapes\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"Y_test:\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reshape datasets into (3, 32, 32) and normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train reshaped: (50000, 3, 32, 32)\n",
            "X_test reshaped: (10000, 3, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "# reshape to (N, 3, 32, 32)\n",
        "X_train = X_train.reshape(-1, 3, 32, 32)\n",
        "X_test = X_test.reshape(-1, 3, 32, 32)\n",
        "\n",
        "print(\"X_train reshaped:\", X_train.shape)\n",
        "print(\"X_test reshaped:\", X_test.shape)\n",
        "\n",
        "# normalize pixel values to [0, 1] and convert to float32 for precision\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_test = X_test.astype(np.float32) / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions for later. Split train into train + validation and iterate through batches during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (45000, 3, 32, 32)\n",
            "Y_train: (45000,)\n",
            "X_val: (5000, 3, 32, 32)\n",
            "Y_val: (5000,)\n"
          ]
        }
      ],
      "source": [
        "def train_val_split(X, Y, ratio=0.1):\n",
        "    \"\"\"\n",
        "    Split the training data into new training and validation sets.\n",
        "    \"\"\"\n",
        "    N = len(X)\n",
        "    random_indices = np.random.permutation(N)\n",
        "    val_size = int(N * ratio)\n",
        "\n",
        "    # calculate validation and new training indices\n",
        "    val_i = random_indices[:val_size]\n",
        "    train_i = random_indices[val_size:]\n",
        "\n",
        "    X_val, Y_val = X[val_i], Y[val_i]\n",
        "    X_train_new, Y_train_new = X[train_i], Y[train_i]\n",
        "\n",
        "    return X_train_new, Y_train_new, X_val, Y_val\n",
        "\n",
        "\n",
        "def batch_generator(X, Y, batch_size=64, random=True):\n",
        "    \"\"\"\n",
        "    Generate batches of data from X and Y with specified batch size.\n",
        "    \"\"\"\n",
        "    N = len(X)\n",
        "    indices = np.arange(N)\n",
        "\n",
        "    # shuffle indices\n",
        "    if random:\n",
        "        indices = np.random.permutation(N)\n",
        "\n",
        "    for start in range(0, N, batch_size):\n",
        "        # determine the end index of the batch, if > N, set to N\n",
        "        end = min(start + batch_size, N)\n",
        "        batch_indices = indices[start:end]\n",
        "\n",
        "        # process batch one by one\n",
        "        yield X[batch_indices], Y[batch_indices]\n",
        "\n",
        "\n",
        "# split training data into new training and validation sets\n",
        "X_train, Y_train, X_val, Y_val = train_val_split(X_train, Y_train, ratio=0.1)\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"X_val:\", X_val.shape)\n",
        "print(\"Y_val:\", Y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2: The Convolution Layer and Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Work in Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "testImg = data_separated.astype(np.float32) / 255.0\n",
        "\n",
        "def convolve(X, filters, padding=0, stride=1):\n",
        "    \"\"\"\n",
        "    Perform convolution on input image X with specified filters and kernel size\n",
        "\n",
        "    X: input image of shape (C, H, W)\n",
        "    filters: shape (num_filters, k_depth, kH, kW)\n",
        "    \"\"\"\n",
        "    # dimensions\n",
        "    num_filters = filters.shape[0]\n",
        "    k_depth = filters.shape[1]\n",
        "    kH = filters.shape[2]\n",
        "    kW = filters.shape[3]\n",
        "    C, H, W = X.shape\n",
        "    kernels = filters\n",
        "\n",
        "    if padding > 0:\n",
        "        X = np.pad(X, ((0,0), (padding, padding), (padding, padding)), mode='constant')\n",
        "\n",
        "    outH = (H - kH + 2 * padding) // stride + 1\n",
        "    outW = (W - kW + 2 * padding) // stride + 1\n",
        "    output = np.zeros((num_filters, outH, outW))\n",
        "\n",
        "    # print(kernels.shape)\n",
        "\n",
        "    for d in range(num_filters):\n",
        "        kernel = kernels[d] # select the d-th kernel\n",
        "\n",
        "        for i in range(outH):\n",
        "            for j in range(outW):\n",
        "                h1 = i * stride\n",
        "                h2 = h1 + kH\n",
        "                w1 = j * stride\n",
        "                w2 = w1 + kW\n",
        "\n",
        "                # perform convolution of the kernel and image region\n",
        "                r = X[:, h1:h2, w1:w2]\n",
        "                output[d, i, j] = np.sum(r * kernel)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RELU Activation and Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "def activation_ReLU(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "\n",
        "def max_pool(X, pool_size=(2, 2), stride=2, padding=0):\n",
        "    \"\"\"\n",
        "    Perform max pooling on input feature map X with specified pool size and stride.\n",
        "\n",
        "    X: input feature map of shape (D, H, W)\n",
        "    \"\"\"\n",
        "    p_height, p_width = pool_size\n",
        "    num_filters, H, W = X.shape\n",
        "\n",
        "    outH = (H - p_height + 2 * padding) // stride + 1\n",
        "    outW = (W - p_width + 2 * padding) // stride + 1\n",
        "    output = np.zeros((num_filters, outH, outW))\n",
        "\n",
        "    for d in range(num_filters):\n",
        "        for i in range(outH):\n",
        "            for j in range(outW):\n",
        "                h1 = i * stride\n",
        "                h2 = h1 + p_height\n",
        "                w1 = j * stride\n",
        "                w2 = w1 + p_width\n",
        "                  \n",
        "                region = X[d, h1:h2, w1:w2]\n",
        "                output[d, i, j] = np.max(region)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def perform_convolutions(X, kernels):\n",
        "    \"\"\"\n",
        "    Performs n amount of convolutions on image X, returning the final feature map\n",
        "    \"\"\"\n",
        "    current = X # keeping track of current conv\n",
        "\n",
        "    for filters in kernels:\n",
        "        conv = convolve(current, filters)\n",
        "        conv_activated = activation_ReLU(conv)\n",
        "        current = max_pool(conv_activated)\n",
        "\n",
        "    return current\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3: The Dense Layer and Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_layer(conv_out, w, b):\n",
        "    \"\"\"\n",
        "    Takes a flattened conv_out and returns a list of 10 values\n",
        "    \"\"\"\n",
        "    dense = conv_out.dot(w) + b\n",
        "    return dense\n",
        "\n",
        "\n",
        "def soft_max(dense_out):\n",
        "    e_x = np.exp(dense_out - np.max(dense_out))\n",
        "    return e_x  / np.sum(e_x)\n",
        "\n",
        "\n",
        "def select_max_prob(probs):\n",
        "    classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', \n",
        "           'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "    \n",
        "    p_index = np.argmax(probs)\n",
        "    prediction = classes[p_index]\n",
        "    confidence = probs[p_index] * 100\n",
        "\n",
        "    return prediction, confidence, p_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_pass(X, w, b, kernel_weights):\n",
        "    \"\"\"\n",
        "    Performs the entire forward pass operation on image X\n",
        "    \"\"\"\n",
        "    conv_output = perform_convolutions(X, kernel_weights).flatten()\n",
        "    dense_out = dense_layer(conv_output, w, b)\n",
        "\n",
        "    probabilities = soft_max(dense_out)\n",
        "    prediction, conf, pred_index = select_max_prob(probabilities)\n",
        "\n",
        "    print(f\"Prediction: {prediction} with a confidence of {conf:.2f}%\")\n",
        "    \n",
        "    return probabilities, conv_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize kernel and dense weights. Then, perform the forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initializing kernel and dense layer weights\n",
        "# THIS IS THE STATE \n",
        "kW1 = np.random.randn(16, 3, 3, 3)\n",
        "kW2 = np.random.randn(32, 16, 3, 3) \n",
        "kW3 = np.random.randn(64, 32, 3, 3)\n",
        "kW = [kW1, kW2, kW3]\n",
        "\n",
        "global_weights = np.random.randn(256, 10)\n",
        "global_biases = np.random.randn(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Airplane with a confidence of 100.00%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.84325307e-94,\n",
              "        0.00000000e+00, 0.00000000e+00]),\n",
              " array([   0.        ,    0.        ,    0.        ,    0.        ,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         158.57996784,   80.20549845,  341.29458201,  440.8912222 ,\n",
              "         565.16279168,  639.89120136,  595.36723006,  554.21569959,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "           0.        ,    0.        ,    0.        ,    7.90319532,\n",
              "          39.47713852,  346.63605007,  769.81563211,  958.90910654,\n",
              "         288.36021908,  237.43376805,  179.83229859,   37.80089679,\n",
              "         713.83962562, 1145.90255996, 1435.4335416 , 1370.3390482 ,\n",
              "          82.91972819,   46.8444423 ,  437.01290618,  539.39342218,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "           0.        ,    0.        ,    4.61732018,    0.        ,\n",
              "         251.28441821,  494.44274291,  644.51200468,  776.28756544,\n",
              "         364.09573658,  539.82661621,  505.84224297,  592.90307298,\n",
              "         343.34460335,  518.75431639,  465.0636428 ,  515.05542821,\n",
              "           0.        ,    0.        ,   27.02405963,  139.41420069,\n",
              "         784.01646499,  876.06197741, 1005.41162304,  926.38663259,\n",
              "          56.56942333,   89.38529747,  165.66903956,  203.35584351,\n",
              "         634.86224759,  562.2706199 ,  549.96893665,  533.29951821,\n",
              "           4.59035328,    0.        ,    0.        ,    0.        ,\n",
              "         918.19720156, 1061.31383884,  942.06444879,  807.51179718,\n",
              "         243.35303969,  247.05109116,  265.73848737,  233.50350742,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         135.03594689,   22.77379615,  211.13397634,  178.71891229,\n",
              "         637.06023935,  613.17376389,  566.26548246,  293.8881688 ,\n",
              "         214.09914141,  133.54797392,    0.        ,    0.        ,\n",
              "         766.87382103,  732.39086161,  685.70519473,  684.42567842,\n",
              "         881.38746298,  992.85294557, 1200.76212425, 1239.54139837,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         645.61490314,  614.90043629, 1027.15986223, 1035.3960184 ,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         337.55577182,  517.7542532 ,  693.27116174,  603.35295063,\n",
              "         260.75713635,  378.48906618,  255.77581135,  354.4493297 ,\n",
              "         187.73782509,  273.0163752 ,  402.06087894,  319.74069171,\n",
              "         443.8003644 ,  613.0961148 ,  664.08042012,  832.04898476,\n",
              "         328.86879707,  292.01235297,  215.37769754,  239.48965334,\n",
              "         236.93486143,  353.3475787 ,  179.37433438,  312.64761057,\n",
              "         468.08803114,  470.06785766,  428.08617641,  370.6051135 ,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         230.91023761,  165.31872309,  168.97266642,  197.49794335,\n",
              "         197.44116227,  421.11754842,  796.64753218,  864.62360197,\n",
              "         599.39535834,  641.82151372,  575.99549996,  681.79538833,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "          50.4713872 ,    0.        ,  523.61145038,  547.56971555,\n",
              "         118.38928524,  202.8916494 ,  244.06053805,  261.78439633,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "           0.        ,    0.        ,   14.76180292,   14.20508294,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         700.72364016,  682.30382715,  781.34689645,  846.96767864,\n",
              "         418.78030835,  476.90611225,  382.29443671,  436.03880922,\n",
              "          71.43299317,   94.21230953,    0.        ,   98.22441296,\n",
              "          47.01568144,  108.59823178,    0.        ,    0.        ,\n",
              "           0.        ,    0.        ,    9.21224101,  187.70553762,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         628.14424447,  756.38932239,  719.82288645,  282.90082351,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         345.67339506,  432.38051675,  460.19005537,  713.61911895,\n",
              "        1030.21129702, 1140.79582214, 1240.75228937, 1261.97956754,\n",
              "         227.51617432,  336.55139082,   51.22333914,  101.85217116,\n",
              "         197.02337768,  531.38478085,  346.65934493,  387.83744503,\n",
              "         227.27970403,  162.92414561,  319.58679021,  290.16260466,\n",
              "           0.        ,    0.        ,    0.        ,    0.        ,\n",
              "          36.69730871,   23.65830605,    0.        ,   33.09912969]))"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forward_pass(testImg, global_weights, global_biases, kW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4: Stochastic Gradient Descent and Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot(Y):\n",
        "    one_hot_vector = np.zeros(10)\n",
        "    one_hot_vector[Y] = 1.0\n",
        "    \n",
        "    return one_hot_vector\n",
        "\n",
        "def stoch_gradient_descent(X, Y, w, b, alpha=0.01):\n",
        "    # probs [] and flattened feature map  is returned\n",
        "    probs, conv_out = forward_pass(X, global_weights, global_biases, kW) \n",
        "    trueY = one_hot(Y)\n",
        "\n",
        "    loss = -np.log(probs[Y] + 1e-9) # small offset to avoid 0 log\n",
        "\n",
        "    # derivative of loss w.r.t Z\n",
        "    dLZ = (probs - trueY)\n",
        "\n",
        "    # derivative of loss w.r.t W\n",
        "    dzW = conv_out\n",
        "\n",
        "    # gradient vector\n",
        "    dLW = np.outer(dzW, dLZ)\n",
        "    dLB = dLZ\n",
        "\n",
        "    # updating weights and biases\n",
        "    new_w = w - (alpha * dLW)\n",
        "    new_b = b - (alpha * dLB)\n",
        "\n",
        "    return new_w, new_b, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the full pipeline on one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = testImg\n",
        "\n",
        "# global_weights, global_biases, loss = stoch_gradient_descent(\n",
        "#     image, \n",
        "#     labels[0], \n",
        "#     global_weights, \n",
        "#     global_biases, \n",
        "#     alpha=0.01\n",
        "# )\n",
        "\n",
        "# print(f\"Loss for this image: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 5: Training the Model on the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Airplane with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Truck with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Cat with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Airplane with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Airplane with a confidence of 100.00%\n",
            "Prediction: Dog with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Truck with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Cat with a confidence of 100.00%\n",
            "Prediction: Cat with a confidence of 100.00%\n",
            "Prediction: Frog with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Airplane with a confidence of 100.00%\n",
            "Prediction: Dog with a confidence of 100.00%\n",
            "Prediction: Cat with a confidence of 100.00%\n",
            "Prediction: Airplane with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Airplane with a confidence of 100.00%\n",
            "Prediction: Cat with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Cat with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Horse with a confidence of 100.00%\n",
            "Prediction: Frog with a confidence of 100.00%\n",
            "Prediction: Deer with a confidence of 100.00%\n",
            "Prediction: Bird with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Ship with a confidence of 100.00%\n",
            "Prediction: Automobile with a confidence of 100.00%\n",
            "Prediction: Truck with a confidence of 100.00%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_batch)):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         global_weights, global_biases, _ = \u001b[43mstoch_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglobal_biases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrate\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     batch_count += \u001b[32m1\u001b[39m\n\u001b[32m     28\u001b[39m correct = \u001b[32m0\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mstoch_gradient_descent\u001b[39m\u001b[34m(X, Y, w, b, alpha)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstoch_gradient_descent\u001b[39m(X, Y, w, b, alpha=\u001b[32m0.01\u001b[39m):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# probs [] and flattened feature map  is returned\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     probs, conv_out = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_biases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkW\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     10\u001b[39m     trueY = one_hot(Y)\n\u001b[32m     12\u001b[39m     loss = -np.log(probs[Y] + \u001b[32m1e-9\u001b[39m) \u001b[38;5;66;03m# small offset to avoid 0 log\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[128]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(X, w, b, kernel_weights)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_pass\u001b[39m(X, w, b, kernel_weights):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Performs the entire forward pass operation on image X\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     conv_output = \u001b[43mperform_convolutions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_weights\u001b[49m\u001b[43m)\u001b[49m.flatten()\n\u001b[32m      6\u001b[39m     dense_out = dense_layer(conv_output, w, b)\n\u001b[32m      8\u001b[39m     probabilities = soft_max(dense_out)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mperform_convolutions\u001b[39m\u001b[34m(X, kernels)\u001b[39m\n\u001b[32m     36\u001b[39m current = X \u001b[38;5;66;03m# keeping track of current conv\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filters \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     conv = \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     conv_activated = activation_ReLU(conv)\n\u001b[32m     41\u001b[39m     current = max_pool(conv_activated)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mconvolve\u001b[39m\u001b[34m(X, filters, padding, stride)\u001b[39m\n\u001b[32m     37\u001b[39m             \u001b[38;5;66;03m# perform convolution of the kernel and image region\u001b[39;00m\n\u001b[32m     38\u001b[39m             r = X[:, h1:h2, w1:w2]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m             output[d, i, j] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2333\u001b[39m, in \u001b[36m_sum_dispatcher\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing `min` or `max` keyword argument when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2328\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m'\u001b[39m, a_min, a_max, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2334\u001b[39m                     initial=\u001b[38;5;28;01mNone\u001b[39;00m, where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[32m   2338\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[32m   2339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue,\n\u001b[32m   2340\u001b[39m         initial=np._NoValue, where=np._NoValue):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "epoch = 20\n",
        "batch_size = 64\n",
        "rate = 0.01 # learning rate\n",
        "loss = [] # will be used to plot loss overtime\n",
        "per_batch = 5\n",
        "\n",
        "# X_train = X_train / 255.0\n",
        "# X_test = X_test / 255.0\n",
        "# X_val = X_val / 255.0\n",
        "\n",
        "for e_num in range(epoch):\n",
        "    batches = batch_generator(X_train, Y_train, batch_size)\n",
        "    batch_count = 0\n",
        "\n",
        "    for X_batch, Y_batch in batches:\n",
        "        for i in range(len(X_batch)):\n",
        "            global_weights, global_biases, _ = stoch_gradient_descent(\n",
        "                X_batch[i], \n",
        "                Y_batch[i], \n",
        "                global_weights, \n",
        "                global_biases, \n",
        "                alpha=rate\n",
        "            )\n",
        "        \n",
        "        batch_count += 1\n",
        "    \n",
        "    correct = 0\n",
        "    total_val = len(X_val) \n",
        "    \n",
        "    for k in range(total_val):\n",
        "        probs, _ = forward_pass(X_val[k], global_weights, global_biases, kW)\n",
        "        if np.argmax(probs) == Y_val[k]:\n",
        "            correct += 1\n",
        "            \n",
        "    final_acc = (correct / total_val) * 100\n",
        "    print(f\"EPOCH {e_num+1} ACCURACY: {final_acc:.2f} %\")\n",
        "    time.sleep(5)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Citation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CIFAR-10 dataset generously provided by __Alex Krizhevskyâ€™s 2009 technical report, Learning Multiple Layers of Features from Tiny Images__"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
