{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aFdhLBpZFjr"
      },
      "source": [
        "### Convolutional Neural Network (CNN) for Processing and Classifying CIFAR-10 Images from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1: Initial Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hau8Ji04ZDa9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "np.random.seed(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load up initial data from CIFAR-10:\n",
        "* 10 classes of images (airplane, automobile, bird...)\n",
        "* 6000 images per class (5000 train, 1000 test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(31.5), np.float64(31.5), np.float64(-0.5))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def load_batch_from_file(file_path):\n",
        "    # load data from a CIFAR-10 batch file using pickle\n",
        "    with open(file_path, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='bytes')\n",
        "    data = np.array(batch[b'data'])\n",
        "    labels = np.array(batch[b'labels'])\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "# reshape data into 3 channels of 32x32 images\n",
        "data, labels = load_batch_from_file('cifar-10-batches-py/data_batch_1')\n",
        "data_separated = data[0].reshape(3, 32, 32)\n",
        "\n",
        "img = data_separated.transpose(1, 2, 0)  # (H, W, C)\n",
        "\n",
        "# display first image for test\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process all training and test batches from cifar-10-batches-py folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (50000, 3072)\n",
            "Y_train: (50000,)\n",
            "X_test: (10000, 3072)\n",
            "Y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "def load_batches():\n",
        "    X_list, Y_list = [], []\n",
        "\n",
        "    # load training batches 1 to 5\n",
        "    for i in range(1, 6):\n",
        "        path = f'cifar-10-batches-py/data_batch_{i}'\n",
        "        data, labels = load_batch_from_file(path)\n",
        "\n",
        "        X_list.append(data)\n",
        "        Y_list.append(labels)\n",
        "\n",
        "    # concatenate all training batches\n",
        "    X_train = np.concatenate(X_list)\n",
        "    Y_train = np.concatenate(Y_list)\n",
        "\n",
        "    # test batch\n",
        "    X_test, Y_test = load_batch_from_file('cifar-10-batches-py/test_batch')\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = load_batches()\n",
        "\n",
        "# shapes\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"Y_test:\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reshape datasets into (3, 32, 32) and normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train reshaped: (50000, 3, 32, 32)\n",
            "X_test reshaped: (10000, 3, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "# reshape to (N, 3, 32, 32)\n",
        "X_train = X_train.reshape(-1, 3, 32, 32)\n",
        "X_test = X_test.reshape(-1, 3, 32, 32)\n",
        "\n",
        "print(\"X_train reshaped:\", X_train.shape)\n",
        "print(\"X_test reshaped:\", X_test.shape)\n",
        "\n",
        "# normalize pixel values to [0, 1] and convert to float32 for precision\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_test = X_test.astype(np.float32) / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions for later. Split train into train + validation and iterate through batches during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (45000, 3, 32, 32)\n",
            "Y_train: (45000,)\n",
            "X_val: (5000, 3, 32, 32)\n",
            "Y_val: (5000,)\n"
          ]
        }
      ],
      "source": [
        "def train_val_split(X, Y, ratio=0.1):\n",
        "    \"\"\"\n",
        "    Split the training data into new training and validation sets.\n",
        "    \"\"\"\n",
        "    N = len(X)\n",
        "    random_indices = np.random.permutation(N)\n",
        "    val_size = int(N * ratio)\n",
        "\n",
        "    # calculate validation and new training indices\n",
        "    val_i = random_indices[:val_size]\n",
        "    train_i = random_indices[val_size:]\n",
        "\n",
        "    X_val, Y_val = X[val_i], Y[val_i]\n",
        "    X_train_new, Y_train_new = X[train_i], Y[train_i]\n",
        "\n",
        "    return X_train_new, Y_train_new, X_val, Y_val\n",
        "\n",
        "\n",
        "def batch_generator(X, Y, batch_size=64, random=True):\n",
        "    \"\"\"\n",
        "    Generate batches of data from X and Y with specified batch size.\n",
        "    \"\"\"\n",
        "    N = len(X)\n",
        "    indices = np.arange(N)\n",
        "\n",
        "    # shuffle indices\n",
        "    if random:\n",
        "        indices = np.random.permutation(N)\n",
        "\n",
        "    for start in range(0, N, batch_size):\n",
        "        # determine the end index of the batch, if > N, set to N\n",
        "        end = min(start + batch_size, N)\n",
        "        batch_indices = indices[start:end]\n",
        "\n",
        "        # process batch one by one\n",
        "        yield X[batch_indices], Y[batch_indices]\n",
        "\n",
        "\n",
        "# split training data into new training and validation sets\n",
        "X_train, Y_train, X_val, Y_val = train_val_split(X_train, Y_train, ratio=0.1)\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"X_val:\", X_val.shape)\n",
        "print(\"Y_val:\", Y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2: The Convolution Layer and Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Work in Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "testImg = data_separated.astype(np.float32) / 255.0\n",
        "\n",
        "def convolve(X, filters, padding=0, stride=1):\n",
        "    \"\"\"\n",
        "    Perform convolution on input image X with specified filters and kernel size\n",
        "\n",
        "    X: input image of shape (C, H, W)\n",
        "    filters: shape (num_filters, k_depth, kH, kW)\n",
        "    \"\"\"\n",
        "    # dimensions\n",
        "    num_filters = filters.shape[0]\n",
        "    k_depth = filters.shape[1]\n",
        "    kH = filters.shape[2]\n",
        "    kW = filters.shape[3]\n",
        "    C, H, W = X.shape\n",
        "    kernels = filters\n",
        "\n",
        "    if padding > 0:\n",
        "        X = np.pad(X, ((0,0), (padding, padding), (padding, padding)), mode='constant')\n",
        "\n",
        "    outH = (H - kH + 2 * padding) // stride + 1\n",
        "    outW = (W - kW + 2 * padding) // stride + 1\n",
        "    output = np.zeros((num_filters, outH, outW))\n",
        "\n",
        "    # print(kernels.shape)\n",
        "\n",
        "    for d in range(num_filters):\n",
        "        kernel = kernels[d] # select the d-th kernel\n",
        "\n",
        "        for i in range(outH):\n",
        "            for j in range(outW):\n",
        "                h1 = i * stride\n",
        "                h2 = h1 + kH\n",
        "                w1 = j * stride\n",
        "                w2 = w1 + kW\n",
        "\n",
        "                # perform convolution of the kernel and image region\n",
        "                r = X[:, h1:h2, w1:w2]\n",
        "                output[d, i, j] = np.sum(r * kernel)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convolve w/ imc2col\n",
        "from numpy.lib.stride_tricks import as_strided, sliding_window_view\n",
        "\n",
        "def convolve_im2col(X, filters, padding=0, stride=1):\n",
        "    \"\"\"\n",
        "    Perform convolution on input images X with specified filters and kernel size\n",
        "\n",
        "    X: input image of shape (N, C, H, W)\n",
        "    filters: shape (num_filters, k_depth, kH, kW)\n",
        "    \"\"\" \n",
        "    num_img, C, H, W = X.shape\n",
        "    num_filters, _, kH, kW = filters.shape\n",
        "\n",
        "    outH = (H - kH + 2 * padding) // stride + 1\n",
        "    outW = (W - kW + 2 * padding) // stride + 1\n",
        "\n",
        "    # image to column\n",
        "    X_padded = np.pad(X, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode=\"constant\")\n",
        "\n",
        "    windows = sliding_window_view(X_padded, (kH, kW), (2, 3))\n",
        "\n",
        "    windows_T = windows.transpose(1, 4, 5, 0, 2, 3)\n",
        "\n",
        "    X_col = windows_T.reshape((C * kH * kW, -1))\n",
        "    filters_flattened = filters.reshape(num_filters, -1)\n",
        "\n",
        "    conv_prod = np.matmul(filters_flattened, X_col)\n",
        "    conv_out = conv_prod.reshape((num_filters, num_img, outH, outW)).transpose((1, 0, 2, 3))\n",
        "\n",
        "    return conv_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RELU Activation and Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def activation_ReLU(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "\n",
        "def max_pool(X, pool_size=(2, 2), stride=2, padding=0):\n",
        "    \"\"\"\n",
        "    Perform max pooling on input feature map X with specified pool size and stride.\n",
        "\n",
        "    X: input feature map of shape (D, H, W)\n",
        "    \"\"\"\n",
        "    p_height, p_width = pool_size\n",
        "    num_filters, H, W = X.shape\n",
        "\n",
        "    outH = (H - p_height + 2 * padding) // stride + 1\n",
        "    outW = (W - p_width + 2 * padding) // stride + 1\n",
        "    output = np.zeros((num_filters, outH, outW))\n",
        "\n",
        "    for d in range(num_filters):\n",
        "        for i in range(outH):\n",
        "            for j in range(outW):\n",
        "                h1 = i * stride\n",
        "                h2 = h1 + p_height\n",
        "                w1 = j * stride\n",
        "                w2 = w1 + p_width\n",
        "                  \n",
        "                region = X[d, h1:h2, w1:w2]\n",
        "                output[d, i, j] = np.max(region)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def perform_convolutions(X, kernels):\n",
        "    \"\"\"\n",
        "    Performs n amount of convolutions on image X, returning the final feature map\n",
        "    \"\"\"\n",
        "    cache = []\n",
        "    current = X # keeping track of current conv\n",
        "\n",
        "    for filters in kernels:\n",
        "        conv = convolve(current, filters)\n",
        "        conv_activated = activation_ReLU(conv)\n",
        "        pool_out = max_pool(conv_activated)\n",
        "\n",
        "        # 4. SAVE EVERYTHING!\n",
        "        # We store a tuple: (Input to this layer, Conv Output, ReLU Output, Pool Output)\n",
        "        layer_memory = {\n",
        "            'input': current,         \n",
        "            'conv_out': conv,         \n",
        "            'relu_out': conv_activated,\n",
        "            'pool_out': pool_out       \n",
        "        }\n",
        "        cache.append(layer_memory)\n",
        "\n",
        "        current = pool_out\n",
        "\n",
        "    return current, cache\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rewritng the Pipeline for Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_pool_window(X, pool_size=(2, 2), stride=2):\n",
        "    \"\"\"\n",
        "    Perform max pooling on input feature map X with specified pool size and stride.\n",
        "\n",
        "    X: input feature map of shape (N, C, H, W)\n",
        "    \"\"\"\n",
        "    pH, pW = pool_size\n",
        "\n",
        "    windows = sliding_window_view(X, (pH, pW), (2, 3))\n",
        "    windows = windows[:, :, ::stride, ::stride, :, :]\n",
        "    \n",
        "    max_out = windows.max(axis=(4, 5))\n",
        "\n",
        "    return max_out\n",
        "\n",
        "\n",
        "def perform_convolutions_col(X, kernels):\n",
        "    \"\"\"\n",
        "    Performs n amount of convolutions on images X, returning the final feature map\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    current = X # keeping track of current conv\n",
        "\n",
        "    for filters in kernels:\n",
        "        conv = convolve_im2col(current, filters, padding=1, stride=1)\n",
        "        conv_activated = activation_ReLU(conv)\n",
        "        pool_out = max_pool_window(conv_activated)\n",
        "\n",
        "        layer_data = {\n",
        "            'input': current,         \n",
        "            'conv_out': conv,         \n",
        "            'relu_out': conv_activated,\n",
        "            'pool_out': pool_out       \n",
        "        }\n",
        "        layers.append(layer_data)\n",
        "\n",
        "        current = pool_out\n",
        "\n",
        "    return current, layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3: The Dense Layer and Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_layer(conv_out, w, b):\n",
        "    \"\"\"\n",
        "    Takes a flattened conv_out and returns a list of 10 values\n",
        "    \"\"\"\n",
        "    dense = conv_out.dot(w) + b\n",
        "    return dense\n",
        "\n",
        "\n",
        "def soft_max(dense_out):\n",
        "    e_x = np.exp(dense_out - np.max(dense_out))\n",
        "    return e_x  / np.sum(e_x)\n",
        "\n",
        "\n",
        "def select_max_prob(probs):\n",
        "    classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', \n",
        "           'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "    \n",
        "    p_indices = np.argmax(probs, axis=1)\n",
        "    \n",
        "    predictions = [classes[idx] for idx in p_indices]\n",
        "    \n",
        "    batch_indices = np.arange(len(probs))\n",
        "    confidences = probs[batch_indices, p_indices] * 100\n",
        "\n",
        "    return predictions, confidences, p_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def soft_max_batch(dense_out):\n",
        "    e_x = np.exp(dense_out - np.max(dense_out, axis=1, keepdims=True))\n",
        "    return e_x  / np.sum(e_x, axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_pass(X, w, b, kernel_weights):\n",
        "    \"\"\"\n",
        "    Performs the entire forward pass operation on image X\n",
        "    \"\"\"\n",
        "    conv_3d, layer_data = perform_convolutions(X, kernel_weights)\n",
        "    conv_flattened = conv_3d.reshape(conv_3d.shape[0], -1)\n",
        "    dense_out = dense_layer(conv_flattened, w, b)\n",
        "\n",
        "    probabilities = soft_max(dense_out)\n",
        "    # print(f\"Prediction: {prediction} with a confidence of {conf:.2f}%\")\n",
        "    \n",
        "    return probabilities, conv_flattened, layer_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_pred(X, Y, w, b, kW):\n",
        "    \"\"\"\n",
        "    Checks if prediction matches the given input image\n",
        "    \"\"\"\n",
        "    probs, _, _ = forward_pass(X, w, b, kW)\n",
        "    prediction, conf, pred_index = select_max_prob(probs)\n",
        "\n",
        "    return pred_index == Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize kernel and dense weights. Then, perform the forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # initializing kernel and dense layer weights\n",
        "# # THIS IS THE STATE \n",
        "# kW1 = np.random.randn(16, 3, 3, 3) * np.sqrt(2 / 27)\n",
        "# kW2 = np.random.randn(32, 16, 3, 3) * np.sqrt(2 / 144)\n",
        "# kW3 = np.random.randn(64, 32, 3, 3) * np.sqrt(2 / 288)\n",
        "# kW = [kW1, kW2, kW3]\n",
        "\n",
        "# global_weights = np.random.randn(1024, 10) * np.sqrt(2 / 1024)\n",
        "# global_biases = np.zeros(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# load up existing weights\n",
        "with open(\"cifar_long_epoch_16.pkl\", \"rb\") as f:\n",
        "    loaded_data= pickle.load(f)\n",
        "\n",
        "kW = loaded_data[\"kernels\"]\n",
        "global_weights = loaded_data[\"w\"]\n",
        "global_biases = loaded_data[\"b\"]\n",
        "# loss_collection = loaded_data[\"loss_collection\"]\n",
        "\n",
        "print(\"Weights loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.00985012, 0.00099161, 0.04604636, 0.08689232, 0.21403652,\n",
              "        0.1575691 , 0.35213448, 0.1305276 , 0.00114204, 0.00080986]),\n",
              " array([0.16321444, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 1.9625959 , 2.23661064,\n",
              "        3.24855822, 3.47375456, 0.43900326, 1.131845  , 1.78007243,\n",
              "        1.57552201, 0.08987642, 0.24396929, 0.        , 0.        ,\n",
              "        0.62432373, 0.18025475, 1.00990088, 1.65769153, 0.        ,\n",
              "        1.57288289, 1.27396941, 1.26839024, 1.85554886, 1.77109015,\n",
              "        2.66015465, 2.09474296, 0.        , 0.68663547, 3.20109954,\n",
              "        2.15497577, 0.        , 0.        , 1.16143551, 1.55202349,\n",
              "        0.        , 1.03638605, 1.28506342, 1.4635757 , 0.58644154,\n",
              "        0.55747275, 1.77861837, 1.54284547, 0.        , 0.        ,\n",
              "        0.39328371, 1.15424704, 0.        , 1.73033609, 0.8038051 ,\n",
              "        0.64851943, 0.        , 0.02175409, 0.7990305 , 1.16497984,\n",
              "        0.69725685, 0.71956435, 1.8314759 , 2.03119345, 1.40169457,\n",
              "        1.41912328, 2.85581709, 1.92086372, 1.11809977, 1.48289473,\n",
              "        2.44849834, 1.92623154, 3.56374202, 2.02324862, 2.30837184,\n",
              "        0.66913461, 1.82042996, 1.95713547, 0.7805763 , 1.22389728,\n",
              "        2.38236618, 2.7990147 , 1.73120684, 0.92991031, 0.42918504,\n",
              "        0.13254588, 0.10188797, 0.        , 1.84208657, 1.06980869,\n",
              "        0.31272706, 0.        , 0.30432828, 0.        , 0.6038624 ,\n",
              "        0.        , 2.24835766, 2.43935653, 2.90614402, 3.56318743,\n",
              "        2.19948889, 2.65167138, 0.24524117, 0.64299675, 2.39173437,\n",
              "        1.50169864, 1.7984997 , 0.77082683, 0.        , 0.0321788 ,\n",
              "        1.24900598, 1.7408173 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 1.60625631, 0.94888376, 1.72123745, 2.53986062,\n",
              "        1.95594551, 1.9008896 , 1.17648089, 1.89910627, 1.69638289,\n",
              "        1.84198675, 3.11004911, 2.50148818, 2.33500777, 2.22773807,\n",
              "        2.27538832, 1.70267409, 0.        , 0.13636829, 0.        ,\n",
              "        0.19055384, 0.32624292, 1.15650661, 0.34905641, 1.21131063,\n",
              "        2.86789046, 2.58616765, 1.83835579, 1.88207998, 3.91313685,\n",
              "        4.38346167, 4.31687567, 4.33630792, 2.91891645, 2.68918651,\n",
              "        2.14767938, 0.78090515, 0.        , 0.        , 0.05304359,\n",
              "        0.2403308 , 0.58725745, 0.        , 0.        , 0.        ,\n",
              "        0.19990905, 1.38122041, 2.35153798, 2.65430827, 2.16771304,\n",
              "        2.05296456, 2.4055298 , 2.03194611, 0.        , 0.        ,\n",
              "        0.        , 0.        , 1.1919084 , 0.84769401, 2.4725252 ,\n",
              "        2.48322765, 0.        , 0.        , 0.        , 0.34258691,\n",
              "        1.04469135, 1.60950461, 0.        , 0.28629303, 0.        ,\n",
              "        0.        , 0.        , 0.32728641, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.26993556, 0.08291288, 0.        ,\n",
              "        0.        , 0.9672482 , 1.65714969, 1.72281623, 2.01534844,\n",
              "        1.27203356, 1.45272739, 0.91288282, 1.74213149, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.50047169, 0.15356564,\n",
              "        0.        , 0.34240056, 0.07738094, 0.00451187, 0.        ,\n",
              "        0.19802924, 0.        , 0.        , 0.        , 0.06426144,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.13827813, 0.11919422,\n",
              "        0.05049689, 0.88435213, 1.25759334, 1.32354925, 0.38960209,\n",
              "        0.44606398, 2.61111428, 2.11929228, 0.45913312, 0.56371629,\n",
              "        0.        , 2.23784827, 1.24474731, 2.62933154, 1.56497791,\n",
              "        0.81357594, 0.84856622, 1.0486937 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.14395386, 0.        ,\n",
              "        0.        ]),\n",
              " [{'input': array([[[0.23137255, 0.16862746, 0.19607843, ..., 0.61960787,\n",
              "            0.59607846, 0.5803922 ],\n",
              "           [0.0627451 , 0.        , 0.07058824, ..., 0.48235294,\n",
              "            0.46666667, 0.47843137],\n",
              "           [0.09803922, 0.0627451 , 0.19215687, ..., 0.4627451 ,\n",
              "            0.47058824, 0.42745098],\n",
              "           ...,\n",
              "           [0.8156863 , 0.7882353 , 0.7764706 , ..., 0.627451  ,\n",
              "            0.21960784, 0.20784314],\n",
              "           [0.7058824 , 0.6784314 , 0.7294118 , ..., 0.72156864,\n",
              "            0.38039216, 0.3254902 ],\n",
              "           [0.69411767, 0.65882355, 0.7019608 , ..., 0.84705883,\n",
              "            0.5921569 , 0.48235294]],\n",
              "   \n",
              "          [[0.24313726, 0.18039216, 0.1882353 , ..., 0.5176471 ,\n",
              "            0.49019608, 0.4862745 ],\n",
              "           [0.07843138, 0.        , 0.03137255, ..., 0.34509805,\n",
              "            0.3254902 , 0.34117648],\n",
              "           [0.09411765, 0.02745098, 0.10588235, ..., 0.32941177,\n",
              "            0.32941177, 0.28627452],\n",
              "           ...,\n",
              "           [0.6666667 , 0.6       , 0.6313726 , ..., 0.52156866,\n",
              "            0.12156863, 0.13333334],\n",
              "           [0.54509807, 0.48235294, 0.5647059 , ..., 0.5803922 ,\n",
              "            0.24313726, 0.20784314],\n",
              "           [0.5647059 , 0.5058824 , 0.5568628 , ..., 0.72156864,\n",
              "            0.4627451 , 0.36078432]],\n",
              "   \n",
              "          [[0.24705882, 0.1764706 , 0.16862746, ..., 0.42352942,\n",
              "            0.4       , 0.40392157],\n",
              "           [0.07843138, 0.        , 0.        , ..., 0.21568628,\n",
              "            0.19607843, 0.22352941],\n",
              "           [0.08235294, 0.        , 0.03137255, ..., 0.19607843,\n",
              "            0.19607843, 0.16470589],\n",
              "           ...,\n",
              "           [0.3764706 , 0.13333334, 0.10196079, ..., 0.27450982,\n",
              "            0.02745098, 0.07843138],\n",
              "           [0.3764706 , 0.16470589, 0.11764706, ..., 0.36862746,\n",
              "            0.13333334, 0.13333334],\n",
              "           [0.45490196, 0.36862746, 0.34117648, ..., 0.54901963,\n",
              "            0.32941177, 0.28235295]]], shape=(3, 32, 32), dtype=float32),\n",
              "   'conv_out': array([[[ 5.20243180e-03,  1.87109790e-01,  4.01516132e-01, ...,\n",
              "             5.68558749e-01,  5.10362943e-01,  4.68913024e-01],\n",
              "           [ 2.71546211e-01,  4.45656637e-01,  5.57950401e-01, ...,\n",
              "             6.09830886e-01,  6.05893278e-01,  5.38098659e-01],\n",
              "           [ 3.98418145e-01,  5.78917704e-01,  5.60189330e-01, ...,\n",
              "             5.00836389e-01,  4.19244685e-01,  3.49750527e-01],\n",
              "           ...,\n",
              "           [ 1.13309244e+00,  1.19355343e+00,  1.17953107e+00, ...,\n",
              "             7.17168509e-01,  5.25720366e-01,  2.16322340e-01],\n",
              "           [ 1.01653572e+00,  1.13810548e+00,  1.23876624e+00, ...,\n",
              "             7.89835232e-01,  8.77532289e-01,  5.06809963e-01],\n",
              "           [ 1.06532067e+00,  1.21647992e+00,  1.33343695e+00, ...,\n",
              "             1.23330079e+00,  1.34950864e+00,  8.69316183e-01]],\n",
              "   \n",
              "          [[-1.57010147e-01, -2.23665786e-01, -3.18980293e-01, ...,\n",
              "            -4.90501665e-01, -5.06717809e-01, -5.19035617e-01],\n",
              "           [-6.03835819e-02, -1.39836647e-01, -3.15981803e-01, ...,\n",
              "            -4.55462816e-01, -4.49943755e-01, -4.44958616e-01],\n",
              "           [-1.84758614e-01, -2.67204831e-01, -3.89081573e-01, ...,\n",
              "            -6.07928087e-01, -6.08239465e-01, -5.47474791e-01],\n",
              "           ...,\n",
              "           [-1.03326435e+00, -1.18671023e+00, -1.02931913e+00, ...,\n",
              "            -6.66812857e-01, -4.15663806e-01, -6.14247882e-01],\n",
              "           [-1.04131599e+00, -1.22930067e+00, -1.18993327e+00, ...,\n",
              "            -5.56995385e-01, -1.62351063e-01, -3.12471403e-01],\n",
              "           [-6.69515811e-01, -8.89605719e-01, -9.93196069e-01, ...,\n",
              "            -1.54873029e-01,  1.48246009e-01, -1.69383441e-02]],\n",
              "   \n",
              "          [[ 2.84827477e-01,  5.02415635e-01,  8.14761630e-01, ...,\n",
              "             1.17333650e+00,  1.07313364e+00,  1.02681586e+00],\n",
              "           [ 2.83598697e-01,  6.04670777e-01,  9.17880200e-01, ...,\n",
              "             8.92634026e-01,  8.87926601e-01,  8.50518557e-01],\n",
              "           [ 5.59617995e-01,  8.27365243e-01,  9.57777987e-01, ...,\n",
              "             7.71297087e-01,  7.14829299e-01,  5.60642361e-01],\n",
              "           ...,\n",
              "           [ 1.22844471e+00,  1.16462436e+00,  1.04379122e+00, ...,\n",
              "             1.42066398e+00,  3.66041960e-01,  1.48331367e-01],\n",
              "           [ 1.32560214e+00,  1.27665815e+00,  1.20809368e+00, ...,\n",
              "             1.46978577e+00,  2.95410480e-01,  2.43022633e-01],\n",
              "           [ 1.57948105e+00,  1.64146280e+00,  1.60658714e+00, ...,\n",
              "             2.05836638e+00,  9.39967491e-01,  6.69139088e-01]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[-3.74809173e-01, -3.57366374e-01, -4.87390046e-01, ...,\n",
              "            -1.10485065e+00, -1.10042335e+00, -1.06863469e+00],\n",
              "           [-3.04659813e-01, -3.12775946e-01, -5.01945584e-01, ...,\n",
              "            -9.68027114e-01, -9.25653984e-01, -8.43998447e-01],\n",
              "           [-4.17826402e-01, -4.38941265e-01, -6.26533312e-01, ...,\n",
              "            -9.40073371e-01, -8.80570114e-01, -7.70519699e-01],\n",
              "           ...,\n",
              "           [-1.34933936e+00, -9.94243259e-01, -9.65326954e-01, ...,\n",
              "            -1.05462584e+00, -1.09853957e+00, -9.22906039e-01],\n",
              "           [-1.41838948e+00, -1.10520400e+00, -1.08465390e+00, ...,\n",
              "            -8.14010527e-01, -8.72407823e-01, -8.20542742e-01],\n",
              "           [-1.38120362e+00, -1.11073989e+00, -1.07558340e+00, ...,\n",
              "            -7.20026639e-01, -8.67193923e-01, -9.28294040e-01]],\n",
              "   \n",
              "          [[ 1.82957704e-01,  8.36747876e-02,  1.68851152e-01, ...,\n",
              "             6.39727912e-01,  6.22000995e-01,  5.96941705e-01],\n",
              "           [ 2.13355449e-01,  1.11523231e-01,  2.12060776e-01, ...,\n",
              "             6.51532883e-01,  6.38272253e-01,  5.69240295e-01],\n",
              "           [ 2.26040318e-01,  1.46885356e-01,  3.52341732e-01, ...,\n",
              "             5.92171630e-01,  5.22973280e-01,  4.55873183e-01],\n",
              "           ...,\n",
              "           [ 1.10137360e+00,  1.08234311e+00,  1.05261123e+00, ...,\n",
              "             1.55736960e-01,  8.02936440e-01,  1.09798548e+00],\n",
              "           [ 9.20312996e-01,  9.19847290e-01,  1.00773590e+00, ...,\n",
              "             1.19848848e-03,  7.79705407e-01,  1.21966344e+00],\n",
              "           [ 8.20154241e-01,  7.36549475e-01,  8.37929939e-01, ...,\n",
              "             5.20354451e-02,  6.77970666e-01,  1.26656993e+00]],\n",
              "   \n",
              "          [[ 2.47019976e-01,  3.10849089e-01,  3.96571651e-01, ...,\n",
              "             5.64445832e-01,  5.80099704e-01,  5.74008612e-01],\n",
              "           [ 2.93441707e-01,  3.21903698e-01,  3.70389320e-01, ...,\n",
              "             5.82659568e-01,  5.91646952e-01,  5.01826823e-01],\n",
              "           [ 3.59301352e-01,  3.60286840e-01,  4.45279394e-01, ...,\n",
              "             5.49076735e-01,  4.49891323e-01,  4.00532822e-01],\n",
              "           ...,\n",
              "           [ 1.39270844e+00,  1.09316413e+00,  1.00765255e+00, ...,\n",
              "             4.75134561e-01,  7.51856789e-01,  7.23581220e-01],\n",
              "           [ 1.27765785e+00,  1.13421974e+00,  1.12877819e+00, ...,\n",
              "             5.64180742e-01,  9.15366814e-01,  7.18016529e-01],\n",
              "           [ 1.14197533e+00,  1.09848585e+00,  1.12676911e+00, ...,\n",
              "             5.36466595e-01,  8.65858514e-01,  7.41162993e-01]]],\n",
              "         shape=(16, 30, 30)),\n",
              "   'relu_out': array([[[5.20243180e-03, 1.87109790e-01, 4.01516132e-01, ...,\n",
              "            5.68558749e-01, 5.10362943e-01, 4.68913024e-01],\n",
              "           [2.71546211e-01, 4.45656637e-01, 5.57950401e-01, ...,\n",
              "            6.09830886e-01, 6.05893278e-01, 5.38098659e-01],\n",
              "           [3.98418145e-01, 5.78917704e-01, 5.60189330e-01, ...,\n",
              "            5.00836389e-01, 4.19244685e-01, 3.49750527e-01],\n",
              "           ...,\n",
              "           [1.13309244e+00, 1.19355343e+00, 1.17953107e+00, ...,\n",
              "            7.17168509e-01, 5.25720366e-01, 2.16322340e-01],\n",
              "           [1.01653572e+00, 1.13810548e+00, 1.23876624e+00, ...,\n",
              "            7.89835232e-01, 8.77532289e-01, 5.06809963e-01],\n",
              "           [1.06532067e+00, 1.21647992e+00, 1.33343695e+00, ...,\n",
              "            1.23330079e+00, 1.34950864e+00, 8.69316183e-01]],\n",
              "   \n",
              "          [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           ...,\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 1.48246009e-01, 0.00000000e+00]],\n",
              "   \n",
              "          [[2.84827477e-01, 5.02415635e-01, 8.14761630e-01, ...,\n",
              "            1.17333650e+00, 1.07313364e+00, 1.02681586e+00],\n",
              "           [2.83598697e-01, 6.04670777e-01, 9.17880200e-01, ...,\n",
              "            8.92634026e-01, 8.87926601e-01, 8.50518557e-01],\n",
              "           [5.59617995e-01, 8.27365243e-01, 9.57777987e-01, ...,\n",
              "            7.71297087e-01, 7.14829299e-01, 5.60642361e-01],\n",
              "           ...,\n",
              "           [1.22844471e+00, 1.16462436e+00, 1.04379122e+00, ...,\n",
              "            1.42066398e+00, 3.66041960e-01, 1.48331367e-01],\n",
              "           [1.32560214e+00, 1.27665815e+00, 1.20809368e+00, ...,\n",
              "            1.46978577e+00, 2.95410480e-01, 2.43022633e-01],\n",
              "           [1.57948105e+00, 1.64146280e+00, 1.60658714e+00, ...,\n",
              "            2.05836638e+00, 9.39967491e-01, 6.69139088e-01]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           ...,\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
              "   \n",
              "          [[1.82957704e-01, 8.36747876e-02, 1.68851152e-01, ...,\n",
              "            6.39727912e-01, 6.22000995e-01, 5.96941705e-01],\n",
              "           [2.13355449e-01, 1.11523231e-01, 2.12060776e-01, ...,\n",
              "            6.51532883e-01, 6.38272253e-01, 5.69240295e-01],\n",
              "           [2.26040318e-01, 1.46885356e-01, 3.52341732e-01, ...,\n",
              "            5.92171630e-01, 5.22973280e-01, 4.55873183e-01],\n",
              "           ...,\n",
              "           [1.10137360e+00, 1.08234311e+00, 1.05261123e+00, ...,\n",
              "            1.55736960e-01, 8.02936440e-01, 1.09798548e+00],\n",
              "           [9.20312996e-01, 9.19847290e-01, 1.00773590e+00, ...,\n",
              "            1.19848848e-03, 7.79705407e-01, 1.21966344e+00],\n",
              "           [8.20154241e-01, 7.36549475e-01, 8.37929939e-01, ...,\n",
              "            5.20354451e-02, 6.77970666e-01, 1.26656993e+00]],\n",
              "   \n",
              "          [[2.47019976e-01, 3.10849089e-01, 3.96571651e-01, ...,\n",
              "            5.64445832e-01, 5.80099704e-01, 5.74008612e-01],\n",
              "           [2.93441707e-01, 3.21903698e-01, 3.70389320e-01, ...,\n",
              "            5.82659568e-01, 5.91646952e-01, 5.01826823e-01],\n",
              "           [3.59301352e-01, 3.60286840e-01, 4.45279394e-01, ...,\n",
              "            5.49076735e-01, 4.49891323e-01, 4.00532822e-01],\n",
              "           ...,\n",
              "           [1.39270844e+00, 1.09316413e+00, 1.00765255e+00, ...,\n",
              "            4.75134561e-01, 7.51856789e-01, 7.23581220e-01],\n",
              "           [1.27765785e+00, 1.13421974e+00, 1.12877819e+00, ...,\n",
              "            5.64180742e-01, 9.15366814e-01, 7.18016529e-01],\n",
              "           [1.14197533e+00, 1.09848585e+00, 1.12676911e+00, ...,\n",
              "            5.36466595e-01, 8.65858514e-01, 7.41162993e-01]]],\n",
              "         shape=(16, 30, 30)),\n",
              "   'pool_out': array([[[0.44565664, 0.57694631, 0.65980983, ..., 0.67615899,\n",
              "            0.67919836, 0.60589328],\n",
              "           [0.63346063, 0.66303293, 0.64158545, ..., 0.64768076,\n",
              "            0.54429582, 0.41924469],\n",
              "           [0.68684061, 0.68861287, 0.63440515, ..., 0.68158839,\n",
              "            0.55858166, 0.7145423 ],\n",
              "           ...,\n",
              "           [0.96579655, 0.69121294, 0.73291725, ..., 0.82731429,\n",
              "            1.18776325, 1.3210024 ],\n",
              "           [1.19355343, 1.17953107, 0.92586324, ..., 0.80345361,\n",
              "            1.00259187, 0.66668279],\n",
              "           [1.21647992, 1.43567724, 1.47419423, ..., 0.54907908,\n",
              "            1.23330079, 1.34950864]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           ...,\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.14824601]],\n",
              "   \n",
              "          [[0.60467078, 1.09891573, 1.1812064 , ..., 1.2347009 ,\n",
              "            1.1733365 , 1.07313364],\n",
              "           [1.02146953, 1.03494811, 0.96615287, ..., 1.04609267,\n",
              "            0.92533672, 0.7148293 ],\n",
              "           [1.10224752, 1.05160802, 0.90339036, ..., 0.90521438,\n",
              "            0.70192254, 0.51677362],\n",
              "           ...,\n",
              "           [1.10283581, 1.04944054, 1.24617825, ..., 1.26081801,\n",
              "            1.86970015, 1.94628978],\n",
              "           [1.22844471, 1.04379122, 1.2255403 , ..., 1.04109108,\n",
              "            1.76474647, 1.18472022],\n",
              "           [1.6414628 , 1.60658714, 1.4674844 , ..., 0.67481049,\n",
              "            2.05836638, 0.93996749]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           ...,\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ]],\n",
              "   \n",
              "          [[0.21335545, 0.29947802, 0.52617345, ..., 0.62043907,\n",
              "            0.66815461, 0.63827225],\n",
              "           [0.26542107, 0.59288466, 0.60955282, ..., 0.57741841,\n",
              "            0.59217163, 0.52297328],\n",
              "           [0.46735992, 0.62143013, 0.65494978, ..., 0.76800266,\n",
              "            0.67083405, 0.61603149],\n",
              "           ...,\n",
              "           [1.12264743, 0.83687385, 0.58756303, ..., 0.72850474,\n",
              "            0.68134248, 0.82107046],\n",
              "           [1.13805754, 1.05261123, 0.90244014, ..., 0.71147268,\n",
              "            0.51948439, 1.09798548],\n",
              "           [0.920313  , 1.05411746, 1.09265713, ..., 0.75440218,\n",
              "            0.52112975, 1.26656993]],\n",
              "   \n",
              "          [[0.3219037 , 0.46814344, 0.55527111, ..., 0.63335833,\n",
              "            0.62270657, 0.59164695],\n",
              "           [0.44973999, 0.59763358, 0.60740237, ..., 0.60294424,\n",
              "            0.55344376, 0.44989132],\n",
              "           [0.54553683, 0.63944675, 0.6911827 , ..., 0.68359844,\n",
              "            0.59933209, 0.52006589],\n",
              "           ...,\n",
              "           [1.12013722, 0.6875805 , 0.65146695, ..., 0.74075006,\n",
              "            0.79887563, 0.70817361],\n",
              "           [1.39270844, 1.00765255, 0.78591479, ..., 0.68319562,\n",
              "            0.59260382, 0.75185679],\n",
              "           [1.27765785, 1.13153281, 1.13015534, ..., 0.63576011,\n",
              "            0.56418074, 0.91536681]]], shape=(16, 15, 15))},\n",
              "  {'input': array([[[0.44565664, 0.57694631, 0.65980983, ..., 0.67615899,\n",
              "            0.67919836, 0.60589328],\n",
              "           [0.63346063, 0.66303293, 0.64158545, ..., 0.64768076,\n",
              "            0.54429582, 0.41924469],\n",
              "           [0.68684061, 0.68861287, 0.63440515, ..., 0.68158839,\n",
              "            0.55858166, 0.7145423 ],\n",
              "           ...,\n",
              "           [0.96579655, 0.69121294, 0.73291725, ..., 0.82731429,\n",
              "            1.18776325, 1.3210024 ],\n",
              "           [1.19355343, 1.17953107, 0.92586324, ..., 0.80345361,\n",
              "            1.00259187, 0.66668279],\n",
              "           [1.21647992, 1.43567724, 1.47419423, ..., 0.54907908,\n",
              "            1.23330079, 1.34950864]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           ...,\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.14824601]],\n",
              "   \n",
              "          [[0.60467078, 1.09891573, 1.1812064 , ..., 1.2347009 ,\n",
              "            1.1733365 , 1.07313364],\n",
              "           [1.02146953, 1.03494811, 0.96615287, ..., 1.04609267,\n",
              "            0.92533672, 0.7148293 ],\n",
              "           [1.10224752, 1.05160802, 0.90339036, ..., 0.90521438,\n",
              "            0.70192254, 0.51677362],\n",
              "           ...,\n",
              "           [1.10283581, 1.04944054, 1.24617825, ..., 1.26081801,\n",
              "            1.86970015, 1.94628978],\n",
              "           [1.22844471, 1.04379122, 1.2255403 , ..., 1.04109108,\n",
              "            1.76474647, 1.18472022],\n",
              "           [1.6414628 , 1.60658714, 1.4674844 , ..., 0.67481049,\n",
              "            2.05836638, 0.93996749]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           ...,\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "            0.        , 0.        ]],\n",
              "   \n",
              "          [[0.21335545, 0.29947802, 0.52617345, ..., 0.62043907,\n",
              "            0.66815461, 0.63827225],\n",
              "           [0.26542107, 0.59288466, 0.60955282, ..., 0.57741841,\n",
              "            0.59217163, 0.52297328],\n",
              "           [0.46735992, 0.62143013, 0.65494978, ..., 0.76800266,\n",
              "            0.67083405, 0.61603149],\n",
              "           ...,\n",
              "           [1.12264743, 0.83687385, 0.58756303, ..., 0.72850474,\n",
              "            0.68134248, 0.82107046],\n",
              "           [1.13805754, 1.05261123, 0.90244014, ..., 0.71147268,\n",
              "            0.51948439, 1.09798548],\n",
              "           [0.920313  , 1.05411746, 1.09265713, ..., 0.75440218,\n",
              "            0.52112975, 1.26656993]],\n",
              "   \n",
              "          [[0.3219037 , 0.46814344, 0.55527111, ..., 0.63335833,\n",
              "            0.62270657, 0.59164695],\n",
              "           [0.44973999, 0.59763358, 0.60740237, ..., 0.60294424,\n",
              "            0.55344376, 0.44989132],\n",
              "           [0.54553683, 0.63944675, 0.6911827 , ..., 0.68359844,\n",
              "            0.59933209, 0.52006589],\n",
              "           ...,\n",
              "           [1.12013722, 0.6875805 , 0.65146695, ..., 0.74075006,\n",
              "            0.79887563, 0.70817361],\n",
              "           [1.39270844, 1.00765255, 0.78591479, ..., 0.68319562,\n",
              "            0.59260382, 0.75185679],\n",
              "           [1.27765785, 1.13153281, 1.13015534, ..., 0.63576011,\n",
              "            0.56418074, 0.91536681]]], shape=(16, 15, 15)),\n",
              "   'conv_out': array([[[ 6.25149367e-01,  7.28502636e-01,  5.54281612e-01, ...,\n",
              "             8.46040882e-01,  8.74720397e-01,  8.37345925e-01],\n",
              "           [ 7.45441210e-01,  9.23242918e-01,  8.53945740e-01, ...,\n",
              "             6.70521280e-01,  6.95888130e-01,  5.68962838e-01],\n",
              "           [ 8.57964477e-01,  9.07119003e-01,  9.90081773e-01, ...,\n",
              "             9.96152630e-01,  8.25478774e-01,  9.44765119e-01],\n",
              "           ...,\n",
              "           [ 1.21311061e+00,  5.86086165e-01,  1.54678122e-01, ...,\n",
              "             5.83795961e-01,  5.20663428e-01,  9.30878954e-01],\n",
              "           [ 1.39721087e+00,  1.31997935e+00,  1.43769974e+00, ...,\n",
              "             9.20574616e-01,  1.22753643e+00,  9.16134892e-01],\n",
              "           [ 1.25289041e+00,  9.46076983e-01,  8.41139220e-01, ...,\n",
              "             1.49901049e+00,  1.74412222e+00,  1.11874291e+00]],\n",
              "   \n",
              "          [[ 8.64119886e-01,  9.63599468e-01,  9.94716430e-01, ...,\n",
              "             1.14715530e+00,  1.15538617e+00,  1.12412558e+00],\n",
              "           [ 1.16617798e+00,  1.09836122e+00,  1.07290039e+00, ...,\n",
              "             8.54771049e-01,  1.33928830e+00,  1.41972355e+00],\n",
              "           [ 1.42008149e+00,  1.24616121e+00,  1.22859838e+00, ...,\n",
              "             1.22052259e+00,  1.09610213e+00,  1.44849629e+00],\n",
              "           ...,\n",
              "           [ 1.44372822e+00,  9.36811319e-01,  6.98662704e-01, ...,\n",
              "             9.51611084e-01,  1.08082613e+00,  1.24889214e+00],\n",
              "           [ 1.86847337e+00,  1.56342050e+00,  1.46644573e+00, ...,\n",
              "             1.42251487e+00,  9.64209944e-01,  1.16778000e+00],\n",
              "           [ 1.91648944e+00,  1.98663134e+00,  1.91058222e+00, ...,\n",
              "             1.18724960e+00,  6.57776527e-01,  1.17383511e+00]],\n",
              "   \n",
              "          [[-5.72634351e-01, -2.55465861e-01, -1.31600669e-01, ...,\n",
              "             1.72375113e-03,  1.92724511e-02,  2.71530135e-01],\n",
              "           [-5.79239595e-01, -3.88127024e-01, -3.32872315e-01, ...,\n",
              "             1.41026200e-02, -1.70939746e-01, -2.08154436e-01],\n",
              "           [-5.69194592e-01, -4.29717196e-01, -4.53563960e-01, ...,\n",
              "             2.72820010e-01,  1.30744993e-02, -3.51564974e-01],\n",
              "           ...,\n",
              "           [-8.92461986e-02,  2.42910160e-01, -1.95868292e-01, ...,\n",
              "            -1.65546940e-01, -5.99811934e-01, -8.48576444e-01],\n",
              "           [-4.45911411e-01,  4.39236854e-02,  3.03072417e-01, ...,\n",
              "            -8.03790919e-01, -9.15474017e-01, -7.43777610e-01],\n",
              "           [-7.59808554e-01, -6.94469774e-01, -4.35982222e-01, ...,\n",
              "             6.25601546e-02,  7.42525702e-02, -1.18642958e-01]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[ 4.25130663e-01,  3.51737882e-01,  4.19344039e-01, ...,\n",
              "             2.84615966e-01,  4.29541569e-02,  7.26121455e-02],\n",
              "           [ 4.55592351e-01,  3.59657169e-01,  4.62333964e-01, ...,\n",
              "             5.76874613e-01,  2.74310308e-01,  4.04145495e-01],\n",
              "           [ 3.00440730e-01,  4.55070390e-01,  2.13041445e-01, ...,\n",
              "             8.12097683e-01,  7.94929409e-01,  4.60676965e-01],\n",
              "           ...,\n",
              "           [ 3.88249812e-01,  4.52154462e-01,  4.29727721e-01, ...,\n",
              "             5.59888315e-01,  1.04824370e+00,  1.09256581e+00],\n",
              "           [ 3.17961438e-01,  5.69400043e-01,  3.64313601e-01, ...,\n",
              "             1.69900453e-01,  6.82919309e-01,  4.65272975e-01],\n",
              "           [ 3.42913857e-01,  3.95916398e-01,  5.38572822e-01, ...,\n",
              "             1.78889245e-01,  6.08021498e-01,  3.86106138e-01]],\n",
              "   \n",
              "          [[ 1.27198759e+00,  1.16382135e+00,  1.11343481e+00, ...,\n",
              "             1.51433836e+00,  1.12881883e+00,  8.47105808e-01],\n",
              "           [ 1.01048800e+00,  8.10823649e-01,  1.09767319e+00, ...,\n",
              "             1.18668942e+00,  8.91739978e-01,  6.07472280e-01],\n",
              "           [ 9.21809513e-01,  1.07713091e+00,  1.03407036e+00, ...,\n",
              "             9.51009761e-01,  5.98864394e-01,  5.51215637e-01],\n",
              "           ...,\n",
              "           [ 2.11873682e+00,  2.49911791e+00,  2.19054003e+00, ...,\n",
              "             9.36773870e-01,  1.35201797e+00,  2.62446138e+00],\n",
              "           [ 1.15853126e+00,  1.93392075e+00,  1.88304377e+00, ...,\n",
              "             1.36558183e+00,  1.41779057e+00,  2.61148955e+00],\n",
              "           [ 1.08334227e+00,  1.51198039e+00,  1.60444385e+00, ...,\n",
              "             1.05287925e+00,  1.80005775e+00,  2.11295123e+00]],\n",
              "   \n",
              "          [[-1.53708998e+00, -1.43876686e+00, -1.39377700e+00, ...,\n",
              "            -1.61170193e+00, -1.64158979e+00, -1.42781617e+00],\n",
              "           [-1.54884301e+00, -1.50175516e+00, -1.43001792e+00, ...,\n",
              "            -1.62854809e+00, -1.53308296e+00, -1.35813061e+00],\n",
              "           [-1.66809019e+00, -1.58751958e+00, -1.69115436e+00, ...,\n",
              "            -1.77827226e+00, -1.70718352e+00, -1.41730815e+00],\n",
              "           ...,\n",
              "           [-1.71308273e+00, -1.85162042e+00, -2.06126397e+00, ...,\n",
              "            -1.75061649e+00, -2.06630506e+00, -1.93471747e+00],\n",
              "           [-1.77329858e+00, -1.78428449e+00, -1.94250921e+00, ...,\n",
              "            -1.67829422e+00, -1.91575915e+00, -1.92017604e+00],\n",
              "           [-1.77250702e+00, -1.83494864e+00, -1.94826610e+00, ...,\n",
              "            -1.57591628e+00, -1.99165367e+00, -2.13579495e+00]]],\n",
              "         shape=(32, 13, 13)),\n",
              "   'relu_out': array([[[6.25149367e-01, 7.28502636e-01, 5.54281612e-01, ...,\n",
              "            8.46040882e-01, 8.74720397e-01, 8.37345925e-01],\n",
              "           [7.45441210e-01, 9.23242918e-01, 8.53945740e-01, ...,\n",
              "            6.70521280e-01, 6.95888130e-01, 5.68962838e-01],\n",
              "           [8.57964477e-01, 9.07119003e-01, 9.90081773e-01, ...,\n",
              "            9.96152630e-01, 8.25478774e-01, 9.44765119e-01],\n",
              "           ...,\n",
              "           [1.21311061e+00, 5.86086165e-01, 1.54678122e-01, ...,\n",
              "            5.83795961e-01, 5.20663428e-01, 9.30878954e-01],\n",
              "           [1.39721087e+00, 1.31997935e+00, 1.43769974e+00, ...,\n",
              "            9.20574616e-01, 1.22753643e+00, 9.16134892e-01],\n",
              "           [1.25289041e+00, 9.46076983e-01, 8.41139220e-01, ...,\n",
              "            1.49901049e+00, 1.74412222e+00, 1.11874291e+00]],\n",
              "   \n",
              "          [[8.64119886e-01, 9.63599468e-01, 9.94716430e-01, ...,\n",
              "            1.14715530e+00, 1.15538617e+00, 1.12412558e+00],\n",
              "           [1.16617798e+00, 1.09836122e+00, 1.07290039e+00, ...,\n",
              "            8.54771049e-01, 1.33928830e+00, 1.41972355e+00],\n",
              "           [1.42008149e+00, 1.24616121e+00, 1.22859838e+00, ...,\n",
              "            1.22052259e+00, 1.09610213e+00, 1.44849629e+00],\n",
              "           ...,\n",
              "           [1.44372822e+00, 9.36811319e-01, 6.98662704e-01, ...,\n",
              "            9.51611084e-01, 1.08082613e+00, 1.24889214e+00],\n",
              "           [1.86847337e+00, 1.56342050e+00, 1.46644573e+00, ...,\n",
              "            1.42251487e+00, 9.64209944e-01, 1.16778000e+00],\n",
              "           [1.91648944e+00, 1.98663134e+00, 1.91058222e+00, ...,\n",
              "            1.18724960e+00, 6.57776527e-01, 1.17383511e+00]],\n",
              "   \n",
              "          [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            1.72375113e-03, 1.92724511e-02, 2.71530135e-01],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            1.41026200e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            2.72820010e-01, 1.30744993e-02, 0.00000000e+00],\n",
              "           ...,\n",
              "           [0.00000000e+00, 2.42910160e-01, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 4.39236854e-02, 3.03072417e-01, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            6.25601546e-02, 7.42525702e-02, 0.00000000e+00]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[4.25130663e-01, 3.51737882e-01, 4.19344039e-01, ...,\n",
              "            2.84615966e-01, 4.29541569e-02, 7.26121455e-02],\n",
              "           [4.55592351e-01, 3.59657169e-01, 4.62333964e-01, ...,\n",
              "            5.76874613e-01, 2.74310308e-01, 4.04145495e-01],\n",
              "           [3.00440730e-01, 4.55070390e-01, 2.13041445e-01, ...,\n",
              "            8.12097683e-01, 7.94929409e-01, 4.60676965e-01],\n",
              "           ...,\n",
              "           [3.88249812e-01, 4.52154462e-01, 4.29727721e-01, ...,\n",
              "            5.59888315e-01, 1.04824370e+00, 1.09256581e+00],\n",
              "           [3.17961438e-01, 5.69400043e-01, 3.64313601e-01, ...,\n",
              "            1.69900453e-01, 6.82919309e-01, 4.65272975e-01],\n",
              "           [3.42913857e-01, 3.95916398e-01, 5.38572822e-01, ...,\n",
              "            1.78889245e-01, 6.08021498e-01, 3.86106138e-01]],\n",
              "   \n",
              "          [[1.27198759e+00, 1.16382135e+00, 1.11343481e+00, ...,\n",
              "            1.51433836e+00, 1.12881883e+00, 8.47105808e-01],\n",
              "           [1.01048800e+00, 8.10823649e-01, 1.09767319e+00, ...,\n",
              "            1.18668942e+00, 8.91739978e-01, 6.07472280e-01],\n",
              "           [9.21809513e-01, 1.07713091e+00, 1.03407036e+00, ...,\n",
              "            9.51009761e-01, 5.98864394e-01, 5.51215637e-01],\n",
              "           ...,\n",
              "           [2.11873682e+00, 2.49911791e+00, 2.19054003e+00, ...,\n",
              "            9.36773870e-01, 1.35201797e+00, 2.62446138e+00],\n",
              "           [1.15853126e+00, 1.93392075e+00, 1.88304377e+00, ...,\n",
              "            1.36558183e+00, 1.41779057e+00, 2.61148955e+00],\n",
              "           [1.08334227e+00, 1.51198039e+00, 1.60444385e+00, ...,\n",
              "            1.05287925e+00, 1.80005775e+00, 2.11295123e+00]],\n",
              "   \n",
              "          [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           ...,\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "           [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
              "         shape=(32, 13, 13)),\n",
              "   'pool_out': array([[[0.92324292, 0.85394574, 0.99236999, 0.94973116, 0.96003707,\n",
              "            0.8747204 ],\n",
              "           [1.01619498, 0.99008177, 1.16516884, 0.93540107, 1.18844427,\n",
              "            0.99615263],\n",
              "           [1.31155772, 1.1807309 , 2.04618757, 1.84897592, 1.82075051,\n",
              "            1.28514407],\n",
              "           [1.02998722, 1.50136885, 1.80266751, 2.04478337, 2.08169002,\n",
              "            2.1445633 ],\n",
              "           [1.42759438, 1.68804586, 1.42246219, 0.97204599, 1.60669339,\n",
              "            1.56757488],\n",
              "           [1.39721087, 1.46474969, 1.6466327 , 1.6207431 , 1.09387675,\n",
              "            1.22753643]],\n",
              "   \n",
              "          [[1.16617798, 1.07290039, 1.0425942 , 1.04932531, 1.08984038,\n",
              "            1.3392883 ],\n",
              "           [1.57097693, 1.27591434, 1.70965993, 1.94172784, 2.17849268,\n",
              "            1.95161275],\n",
              "           [1.49906828, 1.35173561, 2.6816916 , 3.8088413 , 3.38102008,\n",
              "            3.80189447],\n",
              "           [1.34669968, 2.92541488, 2.4676411 , 3.45027012, 3.43127414,\n",
              "            3.8824596 ],\n",
              "           [1.13944921, 2.7787577 , 2.23838386, 1.90799171, 1.7316404 ,\n",
              "            2.29204186],\n",
              "           [1.86847337, 1.46644573, 2.36562479, 2.12988989, 1.39898848,\n",
              "            1.42251487]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.11234577, 0.24130739, 0.15679014,\n",
              "            0.01927245],\n",
              "           [0.        , 0.        , 0.247894  , 0.        , 0.        ,\n",
              "            0.27282001],\n",
              "           [0.30083054, 0.1960762 , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.62969025, 2.32509524, 1.94305866,\n",
              "            0.76420188],\n",
              "           [0.62928583, 1.39017693, 1.2641522 , 1.36274945, 0.73310032,\n",
              "            0.92718918],\n",
              "           [0.24291016, 0.63979093, 1.13598541, 0.84266026, 0.23767317,\n",
              "            0.        ]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[0.45559235, 0.46233396, 0.89353135, 0.64751531, 0.63903622,\n",
              "            0.57687461],\n",
              "           [0.45507039, 0.87218292, 1.47377553, 1.32228191, 1.06765114,\n",
              "            0.81209768],\n",
              "           [1.13530276, 1.77386872, 2.23070573, 1.82872531, 1.72280528,\n",
              "            0.24410836],\n",
              "           [2.33242463, 1.87559082, 1.01483996, 1.20216249, 2.0639289 ,\n",
              "            0.92597105],\n",
              "           [1.08475305, 1.50882417, 0.81515416, 0.60338955, 0.79591687,\n",
              "            0.72869529],\n",
              "           [0.56940004, 0.76154338, 0.78249438, 0.54903246, 0.54582009,\n",
              "            1.0482437 ]],\n",
              "   \n",
              "          [[1.27198759, 1.19931469, 1.10609456, 1.32267516, 1.53613134,\n",
              "            1.51433836],\n",
              "           [1.10101789, 1.03407036, 2.09757945, 1.49438754, 1.67284654,\n",
              "            1.3478164 ],\n",
              "           [1.23032566, 2.61521238, 2.97923857, 2.35028192, 1.95817917,\n",
              "            1.15540898],\n",
              "           [3.89224543, 3.65955733, 3.66779713, 2.74354696, 3.40567985,\n",
              "            0.63814662],\n",
              "           [4.08258686, 2.67809084, 2.46058319, 2.2445633 , 3.37353415,\n",
              "            0.71173677],\n",
              "           [2.49911791, 2.4778806 , 1.66795009, 1.39417436, 1.67234953,\n",
              "            1.41779057]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ]]], shape=(32, 6, 6))},\n",
              "  {'input': array([[[0.92324292, 0.85394574, 0.99236999, 0.94973116, 0.96003707,\n",
              "            0.8747204 ],\n",
              "           [1.01619498, 0.99008177, 1.16516884, 0.93540107, 1.18844427,\n",
              "            0.99615263],\n",
              "           [1.31155772, 1.1807309 , 2.04618757, 1.84897592, 1.82075051,\n",
              "            1.28514407],\n",
              "           [1.02998722, 1.50136885, 1.80266751, 2.04478337, 2.08169002,\n",
              "            2.1445633 ],\n",
              "           [1.42759438, 1.68804586, 1.42246219, 0.97204599, 1.60669339,\n",
              "            1.56757488],\n",
              "           [1.39721087, 1.46474969, 1.6466327 , 1.6207431 , 1.09387675,\n",
              "            1.22753643]],\n",
              "   \n",
              "          [[1.16617798, 1.07290039, 1.0425942 , 1.04932531, 1.08984038,\n",
              "            1.3392883 ],\n",
              "           [1.57097693, 1.27591434, 1.70965993, 1.94172784, 2.17849268,\n",
              "            1.95161275],\n",
              "           [1.49906828, 1.35173561, 2.6816916 , 3.8088413 , 3.38102008,\n",
              "            3.80189447],\n",
              "           [1.34669968, 2.92541488, 2.4676411 , 3.45027012, 3.43127414,\n",
              "            3.8824596 ],\n",
              "           [1.13944921, 2.7787577 , 2.23838386, 1.90799171, 1.7316404 ,\n",
              "            2.29204186],\n",
              "           [1.86847337, 1.46644573, 2.36562479, 2.12988989, 1.39898848,\n",
              "            1.42251487]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.11234577, 0.24130739, 0.15679014,\n",
              "            0.01927245],\n",
              "           [0.        , 0.        , 0.247894  , 0.        , 0.        ,\n",
              "            0.27282001],\n",
              "           [0.30083054, 0.1960762 , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.62969025, 2.32509524, 1.94305866,\n",
              "            0.76420188],\n",
              "           [0.62928583, 1.39017693, 1.2641522 , 1.36274945, 0.73310032,\n",
              "            0.92718918],\n",
              "           [0.24291016, 0.63979093, 1.13598541, 0.84266026, 0.23767317,\n",
              "            0.        ]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[0.45559235, 0.46233396, 0.89353135, 0.64751531, 0.63903622,\n",
              "            0.57687461],\n",
              "           [0.45507039, 0.87218292, 1.47377553, 1.32228191, 1.06765114,\n",
              "            0.81209768],\n",
              "           [1.13530276, 1.77386872, 2.23070573, 1.82872531, 1.72280528,\n",
              "            0.24410836],\n",
              "           [2.33242463, 1.87559082, 1.01483996, 1.20216249, 2.0639289 ,\n",
              "            0.92597105],\n",
              "           [1.08475305, 1.50882417, 0.81515416, 0.60338955, 0.79591687,\n",
              "            0.72869529],\n",
              "           [0.56940004, 0.76154338, 0.78249438, 0.54903246, 0.54582009,\n",
              "            1.0482437 ]],\n",
              "   \n",
              "          [[1.27198759, 1.19931469, 1.10609456, 1.32267516, 1.53613134,\n",
              "            1.51433836],\n",
              "           [1.10101789, 1.03407036, 2.09757945, 1.49438754, 1.67284654,\n",
              "            1.3478164 ],\n",
              "           [1.23032566, 2.61521238, 2.97923857, 2.35028192, 1.95817917,\n",
              "            1.15540898],\n",
              "           [3.89224543, 3.65955733, 3.66779713, 2.74354696, 3.40567985,\n",
              "            0.63814662],\n",
              "           [4.08258686, 2.67809084, 2.46058319, 2.2445633 , 3.37353415,\n",
              "            0.71173677],\n",
              "           [2.49911791, 2.4778806 , 1.66795009, 1.39417436, 1.67234953,\n",
              "            1.41779057]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "            0.        ]]], shape=(32, 6, 6)),\n",
              "   'conv_out': array([[[ 0.16321444, -0.30490425, -0.6339591 , -0.36341074],\n",
              "           [-0.62930121, -1.06337665, -1.3456596 , -0.96463694],\n",
              "           [-1.42999293, -0.8151166 , -0.28539544, -0.21301805],\n",
              "           [-0.74353137, -0.23562418, -0.04800209, -0.37224975]],\n",
              "   \n",
              "          [[-2.09075242, -2.82282534, -2.55475973, -2.73035402],\n",
              "           [-3.44477965, -3.70936286, -3.56985789, -3.33103356],\n",
              "           [-3.40996561, -4.20694459, -3.31555702, -3.3026367 ],\n",
              "           [-2.69518204, -2.29939401, -2.46388562, -2.44802079]],\n",
              "   \n",
              "          [[ 0.76484568,  0.84907697,  1.11584027,  1.45135016],\n",
              "           [ 1.69730358,  1.9625959 ,  2.23661064,  0.67368464],\n",
              "           [ 2.24949143,  2.20579279,  3.47375456,  2.24523901],\n",
              "           [ 3.24855822,  2.62172939,  2.93529507,  1.71837129]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[-0.54161625, -1.08869583, -0.25209524, -0.03603995],\n",
              "           [-0.47261993,  1.56497791,  0.81357594, -0.3311108 ],\n",
              "           [ 0.48793131, -0.3651809 ,  0.72610328, -0.0340452 ],\n",
              "           [ 0.84856622, -0.34000306,  0.52457912,  1.0486937 ]],\n",
              "   \n",
              "          [[-0.90346124, -0.98850659, -0.97276771, -0.6407378 ],\n",
              "           [-1.74608662, -1.79430514, -2.00403107, -1.03577085],\n",
              "           [-1.42494994, -2.11703912, -1.89810859, -1.52797444],\n",
              "           [-1.87573036, -2.50629815, -1.29390571, -1.12393724]],\n",
              "   \n",
              "          [[-0.37472122, -0.22456512, -0.37329147,  0.14395386],\n",
              "           [-0.93255898, -1.92036498, -2.4151637 , -1.51435594],\n",
              "           [-2.38676497, -3.14997796, -3.0238556 , -2.12849393],\n",
              "           [-1.96483545, -1.29700698, -0.69229302, -1.39409378]]],\n",
              "         shape=(64, 4, 4)),\n",
              "   'relu_out': array([[[0.16321444, 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ]],\n",
              "   \n",
              "          [[0.76484568, 0.84907697, 1.11584027, 1.45135016],\n",
              "           [1.69730358, 1.9625959 , 2.23661064, 0.67368464],\n",
              "           [2.24949143, 2.20579279, 3.47375456, 2.24523901],\n",
              "           [3.24855822, 2.62172939, 2.93529507, 1.71837129]],\n",
              "   \n",
              "          ...,\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 1.56497791, 0.81357594, 0.        ],\n",
              "           [0.48793131, 0.        , 0.72610328, 0.        ],\n",
              "           [0.84856622, 0.        , 0.52457912, 1.0486937 ]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ]],\n",
              "   \n",
              "          [[0.        , 0.        , 0.        , 0.14395386],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ],\n",
              "           [0.        , 0.        , 0.        , 0.        ]]],\n",
              "         shape=(64, 4, 4)),\n",
              "   'pool_out': array([[[0.16321444, 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[1.9625959 , 2.23661064],\n",
              "           [3.24855822, 3.47375456]],\n",
              "   \n",
              "          [[0.43900326, 1.131845  ],\n",
              "           [1.78007243, 1.57552201]],\n",
              "   \n",
              "          [[0.08987642, 0.24396929],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.62432373, 0.18025475],\n",
              "           [1.00990088, 1.65769153]],\n",
              "   \n",
              "          [[0.        , 1.57288289],\n",
              "           [1.27396941, 1.26839024]],\n",
              "   \n",
              "          [[1.85554886, 1.77109015],\n",
              "           [2.66015465, 2.09474296]],\n",
              "   \n",
              "          [[0.        , 0.68663547],\n",
              "           [3.20109954, 2.15497577]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [1.16143551, 1.55202349]],\n",
              "   \n",
              "          [[0.        , 1.03638605],\n",
              "           [1.28506342, 1.4635757 ]],\n",
              "   \n",
              "          [[0.58644154, 0.55747275],\n",
              "           [1.77861837, 1.54284547]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.39328371, 1.15424704]],\n",
              "   \n",
              "          [[0.        , 1.73033609],\n",
              "           [0.8038051 , 0.64851943]],\n",
              "   \n",
              "          [[0.        , 0.02175409],\n",
              "           [0.7990305 , 1.16497984]],\n",
              "   \n",
              "          [[0.69725685, 0.71956435],\n",
              "           [1.8314759 , 2.03119345]],\n",
              "   \n",
              "          [[1.40169457, 1.41912328],\n",
              "           [2.85581709, 1.92086372]],\n",
              "   \n",
              "          [[1.11809977, 1.48289473],\n",
              "           [2.44849834, 1.92623154]],\n",
              "   \n",
              "          [[3.56374202, 2.02324862],\n",
              "           [2.30837184, 0.66913461]],\n",
              "   \n",
              "          [[1.82042996, 1.95713547],\n",
              "           [0.7805763 , 1.22389728]],\n",
              "   \n",
              "          [[2.38236618, 2.7990147 ],\n",
              "           [1.73120684, 0.92991031]],\n",
              "   \n",
              "          [[0.42918504, 0.13254588],\n",
              "           [0.10188797, 0.        ]],\n",
              "   \n",
              "          [[1.84208657, 1.06980869],\n",
              "           [0.31272706, 0.        ]],\n",
              "   \n",
              "          [[0.30432828, 0.        ],\n",
              "           [0.6038624 , 0.        ]],\n",
              "   \n",
              "          [[2.24835766, 2.43935653],\n",
              "           [2.90614402, 3.56318743]],\n",
              "   \n",
              "          [[2.19948889, 2.65167138],\n",
              "           [0.24524117, 0.64299675]],\n",
              "   \n",
              "          [[2.39173437, 1.50169864],\n",
              "           [1.7984997 , 0.77082683]],\n",
              "   \n",
              "          [[0.        , 0.0321788 ],\n",
              "           [1.24900598, 1.7408173 ]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[1.60625631, 0.94888376],\n",
              "           [1.72123745, 2.53986062]],\n",
              "   \n",
              "          [[1.95594551, 1.9008896 ],\n",
              "           [1.17648089, 1.89910627]],\n",
              "   \n",
              "          [[1.69638289, 1.84198675],\n",
              "           [3.11004911, 2.50148818]],\n",
              "   \n",
              "          [[2.33500777, 2.22773807],\n",
              "           [2.27538832, 1.70267409]],\n",
              "   \n",
              "          [[0.        , 0.13636829],\n",
              "           [0.        , 0.19055384]],\n",
              "   \n",
              "          [[0.32624292, 1.15650661],\n",
              "           [0.34905641, 1.21131063]],\n",
              "   \n",
              "          [[2.86789046, 2.58616765],\n",
              "           [1.83835579, 1.88207998]],\n",
              "   \n",
              "          [[3.91313685, 4.38346167],\n",
              "           [4.31687567, 4.33630792]],\n",
              "   \n",
              "          [[2.91891645, 2.68918651],\n",
              "           [2.14767938, 0.78090515]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.05304359, 0.2403308 ]],\n",
              "   \n",
              "          [[0.58725745, 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.19990905, 1.38122041],\n",
              "           [2.35153798, 2.65430827]],\n",
              "   \n",
              "          [[2.16771304, 2.05296456],\n",
              "           [2.4055298 , 2.03194611]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[1.1919084 , 0.84769401],\n",
              "           [2.4725252 , 2.48322765]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.34258691]],\n",
              "   \n",
              "          [[1.04469135, 1.60950461],\n",
              "           [0.        , 0.28629303]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.32728641]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.26993556, 0.08291288],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.9672482 , 1.65714969],\n",
              "           [1.72281623, 2.01534844]],\n",
              "   \n",
              "          [[1.27203356, 1.45272739],\n",
              "           [0.91288282, 1.74213149]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.50047169, 0.15356564],\n",
              "           [0.        , 0.34240056]],\n",
              "   \n",
              "          [[0.07738094, 0.00451187],\n",
              "           [0.        , 0.19802924]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.06426144]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.13827813, 0.11919422],\n",
              "           [0.05049689, 0.88435213]],\n",
              "   \n",
              "          [[1.25759334, 1.32354925],\n",
              "           [0.38960209, 0.44606398]],\n",
              "   \n",
              "          [[2.61111428, 2.11929228],\n",
              "           [0.45913312, 0.56371629]],\n",
              "   \n",
              "          [[0.        , 2.23784827],\n",
              "           [1.24474731, 2.62933154]],\n",
              "   \n",
              "          [[1.56497791, 0.81357594],\n",
              "           [0.84856622, 1.0486937 ]],\n",
              "   \n",
              "          [[0.        , 0.        ],\n",
              "           [0.        , 0.        ]],\n",
              "   \n",
              "          [[0.        , 0.14395386],\n",
              "           [0.        , 0.        ]]])}])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forward_pass(testImg, global_weights, global_biases, kW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4: Stochastic Gradient Descent and Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot(Y):\n",
        "    one_hot_vector = np.zeros(10)\n",
        "    one_hot_vector[Y] = 1.0\n",
        "    \n",
        "    return one_hot_vector\n",
        "\n",
        "\n",
        "def stoch_gradient_descent(X, Y, w, b, kernels, alpha=0.01):\n",
        "    # probs [] and flattened feature map  is returned\n",
        "    probs, conv_out, cache = forward_pass(X, w, b, kernels) \n",
        "\n",
        "    loss = -np.log(probs[Y] + 1e-9) # small offset to avoid 0 log\n",
        "\n",
        "    new_w, new_b, gradients = backward_pass(\n",
        "        probs, Y, w, b, conv_out, cache, kernels, alpha\n",
        "    )\n",
        "    \n",
        "    # Re-pack the kernels\n",
        "    new_kernels = []\n",
        "    for i in range(len(gradients)):\n",
        "        new_k = kernels[i] - (alpha * gradients[i])\n",
        "\n",
        "        new_kernels.append(new_k)\n",
        "\n",
        "    return new_w, new_b, loss, new_kernels\n",
        "\n",
        "\n",
        "def calc_input_gradients(d_conv_out, kernel):\n",
        "    \"\"\"\n",
        "    Calculates the error for the preceding convolution layer\n",
        "    \"\"\"\n",
        "    # flip and tranpose so filters and channels are swapped\n",
        "    k = np.flip(kernel, axis=(2, 3)).transpose(1, 0, 2, 3)\n",
        "    padding = kernel.shape[2] - 1\n",
        "\n",
        "    d_input = convolve(d_conv_out, k, padding=padding)\n",
        "\n",
        "    return d_input\n",
        "\n",
        "\n",
        "def backward_pass(probs, Y, w, b, conv_out, cache, kernels, alpha=0.01):\n",
        "    \"\"\"\n",
        "    Handles the backward pass from Loss -> Dense -> Conv Output.\n",
        "    \"\"\"\n",
        "    trueY = one_hot(Y)\n",
        "    dLZ = (probs - trueY)\n",
        "    \n",
        "    # derivative of loss w.r.t W\n",
        "    dzW = conv_out\n",
        "    \n",
        "    # d of loss w.r.t weights and biases\n",
        "    dLW = np.outer(dzW, dLZ)\n",
        "    dLB = dLZ\n",
        "    \n",
        "    d_flattened = w.dot(dLZ)\n",
        "    \n",
        "    # update Dense Weights & Biases\n",
        "    new_w = w - (alpha * dLW)\n",
        "    new_b = b - (alpha * dLB)\n",
        "    \n",
        "    layer3_data = cache[-1] \n",
        "    p3 = layer3_data['pool_out']   \n",
        "\n",
        "    # Reshape flat error back to 3D\n",
        "    current_error = d_flattened.reshape(p3.shape)\n",
        "\n",
        "    gradients = []\n",
        "    for i in reversed(range(len(kernels))):\n",
        "        layer_data = cache[i]\n",
        "\n",
        "        a_i = layer_data['relu_out'] \n",
        "        c_i = layer_data['conv_out']  \n",
        "        layer_input = layer_data['input']   \n",
        "\n",
        "        d_relu_out = reverse_max_pool(current_error, a_i)\n",
        "        d_conv_out = reverse_ReLU(d_relu_out, c_i) # the error map\n",
        "        d_kWi = backward_convolution(d_conv_out, layer_input)\n",
        "\n",
        "        gradients.insert(0, d_kWi)\n",
        "\n",
        "        d_input = calc_input_gradients(d_conv_out, kernels[i])\n",
        "\n",
        "        current_error = d_input\n",
        "\n",
        "\n",
        "    return new_w, new_b, gradients\n",
        "\n",
        "\n",
        "# work in progress\n",
        "def backward_convolution(d_conv_out, X_input, kernel_size=(3,3)):\n",
        "    \"\"\"\n",
        "    Calculates the gradient for the kernels (weights).\n",
        "    \n",
        "    d_conv_out: Error map from the next layer (Num_Filters, Out_H, Out_W)\n",
        "    X_input:    Input that went into the layer (Channels, In_H, In_W)\n",
        "    \"\"\"\n",
        "    num_filters, d_h, d_w = d_conv_out.shape\n",
        "    channels, img_h, img_w = X_input.shape\n",
        "    k_h, k_w = kernel_size\n",
        "    \n",
        "    # Initialize gradient block: (Filters, Channels, 3, 3)\n",
        "    d_kernels = np.zeros((num_filters, channels, k_h, k_w))\n",
        "    \n",
        "    for f in range(num_filters):\n",
        "        for c in range(channels):\n",
        "            for i in range(k_h):\n",
        "                for j in range(k_w):\n",
        "                    # We slide the input \"window\" over the error map\n",
        "                    # This tells us how much the pixel at (i,j) contributed to the total error\n",
        "                    input_slice = X_input[c, i:i+d_h, j:j+d_w]\n",
        "                    \n",
        "                    d_kernels[f, c, i, j] = np.sum(input_slice * d_conv_out[f])\n",
        "                    \n",
        "    return d_kernels\n",
        "\n",
        "\n",
        "def reverse_ReLU(d_out, X_input):\n",
        "    d_input = d_out.copy() \n",
        "    d_input[X_input <= 0] = 0\n",
        "\n",
        "    return d_input\n",
        "\n",
        "\n",
        "def reverse_max_pool(d_pool_out, x_conv, pool_size=(2, 2), stride=2):\n",
        "    # Unpack the shape of the gradient coming from the next layer\n",
        "    (num_filters, out_h, out_w) = d_pool_out.shape\n",
        "    \n",
        "    # Initialize the gradient for the previous layer with zeros (same shape as input)\n",
        "    d_pool_in = np.zeros_like(x_conv)\n",
        "    \n",
        "    p_h, p_w = pool_size\n",
        "\n",
        "    # Loop through every pixel of the gradient\n",
        "    for f in range(num_filters):\n",
        "        for i in range(out_h):\n",
        "            for j in range(out_w):\n",
        "                # Find the corners of the current \"slice\" (the 2x2 box)\n",
        "                h_start = i * stride\n",
        "                h_end = h_start + p_h\n",
        "                w_start = j * stride\n",
        "                w_end = w_start + p_w\n",
        "                \n",
        "                x_slice = x_conv[f, h_start:h_end, w_start:w_end]\n",
        "                mask = (x_slice == np.max(x_slice))\n",
        "                \n",
        "                d_pool_in[f, h_start:h_end, w_start:w_end] += mask * d_pool_out[f, i, j]\n",
        "                \n",
        "    return d_pool_in\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the full pipeline on one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = testImg\n",
        "\n",
        "# global_weights, global_biases, loss = stoch_gradient_descent(\n",
        "#     image, \n",
        "#     labels[0], \n",
        "#     global_weights, \n",
        "#     global_biases, \n",
        "#     alpha=0.01\n",
        "# )\n",
        "\n",
        "# print(f\"Loss for this image: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 5: Training the Model on the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 12----\n",
            "EPOCH 12 ACCURACY: 53.42 %\n",
            "-> Checkpoint Saved.\n",
            "EPOCH 13----\n",
            "EPOCH 13 ACCURACY: 54.06 %\n",
            "-> Checkpoint Saved.\n",
            "EPOCH 14----\n",
            "EPOCH 14 ACCURACY: 54.78 %\n",
            "-> Checkpoint Saved.\n",
            "EPOCH 15----\n",
            "EPOCH 15 ACCURACY: 55.56 %\n",
            "-> Checkpoint Saved.\n",
            "EPOCH 16----\n",
            "EPOCH 16 ACCURACY: 55.94 %\n",
            "-> Checkpoint Saved.\n",
            "EPOCH 17----\n",
            "EPOCH 17 ACCURACY: 54.66 %\n",
            "-> Checkpoint Saved.\n",
            "EPOCH 18----\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_batch)):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         global_weights, global_biases, loss, kW = \u001b[43mstoch_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglobal_biases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrate\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m         loss_collection.append(loss)\n\u001b[32m     37\u001b[39m     batch_count += \u001b[32m1\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mstoch_gradient_descent\u001b[39m\u001b[34m(X, Y, w, b, kernels, alpha)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstoch_gradient_descent\u001b[39m(X, Y, w, b, kernels, alpha=\u001b[32m0.01\u001b[39m):\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# probs [] and flattened feature map  is returned\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     probs, conv_out, cache = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernels\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     12\u001b[39m     loss = -np.log(probs[Y] + \u001b[32m1e-9\u001b[39m) \u001b[38;5;66;03m# small offset to avoid 0 log\u001b[39;00m\n\u001b[32m     14\u001b[39m     new_w, new_b, gradients = backward_pass(\n\u001b[32m     15\u001b[39m         probs, Y, w, b, conv_out, cache, kernels, alpha\n\u001b[32m     16\u001b[39m     )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(X, w, b, kernel_weights)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_pass\u001b[39m(X, w, b, kernel_weights):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Performs the entire forward pass operation on image X\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     conv_3d, cache = \u001b[43mperform_convolutions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     conv_output = conv_3d.flatten()\n\u001b[32m      7\u001b[39m     dense_out = dense_layer(conv_output, w, b)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mperform_convolutions\u001b[39m\u001b[34m(X, kernels)\u001b[39m\n\u001b[32m     37\u001b[39m current = X \u001b[38;5;66;03m# keeping track of current conv\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filters \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     conv = \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     conv_activated = activation_ReLU(conv)\n\u001b[32m     42\u001b[39m     pool_out = max_pool(conv_activated)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mconvolve\u001b[39m\u001b[34m(X, filters, padding, stride)\u001b[39m\n\u001b[32m     37\u001b[39m             \u001b[38;5;66;03m# perform convolution of the kernel and image region\u001b[39;00m\n\u001b[32m     38\u001b[39m             r = X[:, h1:h2, w1:w2]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m             output[d, i, j] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2333\u001b[39m, in \u001b[36m_sum_dispatcher\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing `min` or `max` keyword argument when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2328\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m'\u001b[39m, a_min, a_max, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2334\u001b[39m                     initial=\u001b[38;5;28;01mNone\u001b[39;00m, where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[32m   2338\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[32m   2339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue,\n\u001b[32m   2340\u001b[39m         initial=np._NoValue, where=np._NoValue):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "epoch = 30\n",
        "batch_size = 64\n",
        "rate = 0.0001 # learning rate\n",
        "loss_collection = [] # will be used to plot loss overtime\n",
        "per_batch = 5\n",
        "\n",
        "# X_train = X_train / 255.0\n",
        "# X_test = X_test / 255.0\n",
        "# X_val = X_val / 255.0\n",
        "\n",
        "# small set for testing\n",
        "small_X = X_train[:25000]\n",
        "small_Y = Y_train[:25000]\n",
        "\n",
        "small_X_val = X_val\n",
        "small_Y_val = Y_val\n",
        "\n",
        "for e_num in range(11, epoch):\n",
        "    print(f\"EPOCH {e_num+1}----\")\n",
        "    batches = batch_generator(small_X, small_Y, batch_size)\n",
        "    batch_count = 0\n",
        "\n",
        "    for X_batch, Y_batch in batches:\n",
        "        for i in range(len(X_batch)):\n",
        "            global_weights, global_biases, loss, kW = stoch_gradient_descent(\n",
        "                X_batch[i], \n",
        "                Y_batch[i], \n",
        "                global_weights, \n",
        "                global_biases, \n",
        "                kW,\n",
        "                alpha=rate\n",
        "            )\n",
        "            \n",
        "            loss_collection.append(loss)\n",
        "        \n",
        "        batch_count += 1\n",
        "    \n",
        "    correct = 0\n",
        "    total_val = len(small_X_val) \n",
        "    \n",
        "    for k in range(len(small_X_val)):\n",
        "        probs, _, _ = forward_pass(small_X_val[k], global_weights, global_biases, kW)\n",
        "        if np.argmax(probs) == small_Y_val[k]:\n",
        "            correct += 1\n",
        "            \n",
        "    final_acc = (correct / total_val) * 100\n",
        "    print(f\"EPOCH {e_num+1} ACCURACY: {final_acc:.2f} %\")\n",
        "    if final_acc > 58:\n",
        "        rate = 0.00005  # Slow down 10x to take tiny, careful steps\n",
        "\n",
        "    checkpoint = {\n",
        "        \"kernels\": kW,\n",
        "        \"w\": global_weights,\n",
        "        \"b\": global_biases,\n",
        "        \"loss\": loss_collection\n",
        "    }\n",
        "    \n",
        "    with open(f\"cifar_long_epoch_{e_num+1}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(checkpoint, f)\n",
        "    print(f\"-> Checkpoint Saved.\")\n",
        "\n",
        "    if final_acc >= 65:\n",
        "        print(\"TRAIN END----Accuracy has surpassed 65.00%\")\n",
        "        break\n",
        "\n",
        "    time.sleep(5)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save weights immediately after the loop finishes\n",
        "# checkpoint = {\n",
        "#     \"kernels\": kW,\n",
        "#     \"w\": global_weights,\n",
        "#     \"b\": global_biases,\n",
        "#     \"loss_history\": loss_collection\n",
        "# }\n",
        "\n",
        "# with open(\"cifar_10k_run.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(checkpoint, f)\n",
        "\n",
        "# print(\"Model saved to 'cifar_10k_run.pkl'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy with the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "640 of 10000 images processed with accuracy 57.66 %\n",
            "1280 of 10000 images processed with accuracy 55.86 %\n",
            "1920 of 10000 images processed with accuracy 56.25 %\n",
            "2560 of 10000 images processed with accuracy 56.13 %\n",
            "3200 of 10000 images processed with accuracy 55.50 %\n",
            "3840 of 10000 images processed with accuracy 55.47 %\n",
            "4480 of 10000 images processed with accuracy 55.67 %\n",
            "5120 of 10000 images processed with accuracy 55.84 %\n",
            "5760 of 10000 images processed with accuracy 56.04 %\n",
            "6400 of 10000 images processed with accuracy 56.05 %\n",
            "7040 of 10000 images processed with accuracy 56.11 %\n",
            "7680 of 10000 images processed with accuracy 56.33 %\n",
            "8320 of 10000 images processed with accuracy 56.15 %\n",
            "8960 of 10000 images processed with accuracy 56.04 %\n",
            "9600 of 10000 images processed with accuracy 56.17 %\n",
            "TEST ACCURACY : 56.17 %\n"
          ]
        }
      ],
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "batches = batch_generator(X_test, Y_test, batch_size=64)\n",
        "\n",
        "for X_batch, Y_batch in batches:\n",
        "    for i in range(len(X_batch)):\n",
        "        if check_pred(X_batch[i], Y_batch[i], global_weights, global_biases, kW):\n",
        "            correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    if total % 640 == 0:\n",
        "        print(f\"{total} of {len(X_test)} images processed with accuracy {(correct / total) * 100:.2f} %\")\n",
        "\n",
        "\n",
        "print(f\"TEST ACCURACY : {(correct / total) * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Citation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CIFAR-10 dataset generously provided by __Alex Krizhevskys 2009 technical report, Learning Multiple Layers of Features from Tiny Images__"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
