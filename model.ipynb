{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aFdhLBpZFjr"
      },
      "source": [
        "### Convolutional Neural Network (CNN) for Processing and Classifying CIFAR-10 Images from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1: Initial Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "hau8Ji04ZDa9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "np.random.seed(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load up initial data from CIFAR-10:\n",
        "* 10 classes of images (airplane, automobile, bird...)\n",
        "* 6000 images per class (5000 train, 1000 test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(31.5), np.float64(31.5), np.float64(-0.5))"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def load_batch_from_file(file_path):\n",
        "    # load data from a CIFAR-10 batch file using pickle\n",
        "    with open(file_path, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='bytes')\n",
        "    data = np.array(batch[b'data'])\n",
        "    labels = np.array(batch[b'labels'])\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "# reshape data into 3 channels of 32x32 images\n",
        "data, labels = load_batch_from_file('cifar-10-batches-py/data_batch_1')\n",
        "data_separated = data[0].reshape(3, 32, 32)\n",
        "\n",
        "img = data_separated.transpose(1, 2, 0)  # (H, W, C)\n",
        "\n",
        "# display first image for test\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process all training and test batches from cifar-10-batches-py folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (50000, 3072)\n",
            "Y_train: (50000,)\n",
            "X_test: (10000, 3072)\n",
            "Y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "def load_batches():\n",
        "    X_list, Y_list = [], []\n",
        "\n",
        "    # load training batches 1 to 5\n",
        "    for i in range(1, 6):\n",
        "        path = f'cifar-10-batches-py/data_batch_{i}'\n",
        "        data, labels = load_batch_from_file(path)\n",
        "\n",
        "        X_list.append(data)\n",
        "        Y_list.append(labels)\n",
        "\n",
        "    # concatenate all training batches\n",
        "    X_train = np.concatenate(X_list)\n",
        "    Y_train = np.concatenate(Y_list)\n",
        "\n",
        "    # test batch\n",
        "    X_test, Y_test = load_batch_from_file('cifar-10-batches-py/test_batch')\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = load_batches()\n",
        "\n",
        "# shapes\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"Y_test:\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reshape datasets into (3, 32, 32) and normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train reshaped: (50000, 3, 32, 32)\n",
            "X_test reshaped: (10000, 3, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "# reshape to (N, 3, 32, 32)\n",
        "X_train = X_train.reshape(-1, 3, 32, 32)\n",
        "X_test = X_test.reshape(-1, 3, 32, 32)\n",
        "\n",
        "print(\"X_train reshaped:\", X_train.shape)\n",
        "print(\"X_test reshaped:\", X_test.shape)\n",
        "\n",
        "# normalize pixel values to [0, 1] and convert to float32 for precision\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_test = X_test.astype(np.float32) / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions for later. Split train into train + validation and iterate through batches during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (45000, 3, 32, 32)\n",
            "Y_train: (45000,)\n",
            "X_val: (5000, 3, 32, 32)\n",
            "Y_val: (5000,)\n"
          ]
        }
      ],
      "source": [
        "def train_val_split(X, Y, ratio=0.1):\n",
        "    \"\"\"\n",
        "    Split the training data into new training and validation sets.\n",
        "    \"\"\"\n",
        "    N = len(X)\n",
        "    random_indices = np.random.permutation(N)\n",
        "    val_size = int(N * ratio)\n",
        "\n",
        "    # calculate validation and new training indices\n",
        "    val_i = random_indices[:val_size]\n",
        "    train_i = random_indices[val_size:]\n",
        "\n",
        "    X_val, Y_val = X[val_i], Y[val_i]\n",
        "    X_train_new, Y_train_new = X[train_i], Y[train_i]\n",
        "\n",
        "    return X_train_new, Y_train_new, X_val, Y_val\n",
        "\n",
        "\n",
        "def batch_generator(X, Y, batch_size=64, random=True):\n",
        "    \"\"\"\n",
        "    Generate batches of data from X and Y with specified batch size.\n",
        "    \"\"\"\n",
        "    N = len(X)\n",
        "    indices = np.arange(N)\n",
        "\n",
        "    # shuffle indices\n",
        "    if random:\n",
        "        indices = np.random.permutation(N)\n",
        "\n",
        "    for start in range(0, N, batch_size):\n",
        "        # determine the end index of the batch, if > N, set to N\n",
        "        end = min(start + batch_size, N)\n",
        "        batch_indices = indices[start:end]\n",
        "\n",
        "        # process batch one by one\n",
        "        yield X[batch_indices], Y[batch_indices]\n",
        "\n",
        "\n",
        "# split training data into new training and validation sets\n",
        "X_train, Y_train, X_val, Y_val = train_val_split(X_train, Y_train, ratio=0.1)\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"Y_train:\", Y_train.shape)\n",
        "print(\"X_val:\", X_val.shape)\n",
        "print(\"Y_val:\", Y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2: The Convolution Layer and Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Work in Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "testImg = data_separated.astype(np.float32) / 255.0\n",
        "\n",
        "def convolve(X, filters, padding=0, stride=1):\n",
        "    \"\"\"\n",
        "    Perform convolution on input image X with specified filters and kernel size\n",
        "\n",
        "    X: input image of shape (C, H, W)\n",
        "    filters: shape (num_filters, k_depth, kH, kW)\n",
        "    \"\"\"\n",
        "    # dimensions\n",
        "    num_filters = filters.shape[0]\n",
        "    k_depth = filters.shape[1]\n",
        "    kH = filters.shape[2]\n",
        "    kW = filters.shape[3]\n",
        "    C, H, W = X.shape\n",
        "    kernels = filters\n",
        "\n",
        "    if padding > 0:\n",
        "        X = np.pad(X, ((0,0), (padding, padding), (padding, padding)), mode='constant')\n",
        "\n",
        "    outH = (H - kH + 2 * padding) // stride + 1\n",
        "    outW = (W - kW + 2 * padding) // stride + 1\n",
        "    output = np.zeros((num_filters, outH, outW))\n",
        "\n",
        "    # print(kernels.shape)\n",
        "\n",
        "    for d in range(num_filters):\n",
        "        kernel = kernels[d] # select the d-th kernel\n",
        "\n",
        "        for i in range(outH):\n",
        "            for j in range(outW):\n",
        "                h1 = i * stride\n",
        "                h2 = h1 + kH\n",
        "                w1 = j * stride\n",
        "                w2 = w1 + kW\n",
        "\n",
        "                # perform convolution of the kernel and image region\n",
        "                r = X[:, h1:h2, w1:w2]\n",
        "                output[d, i, j] = np.sum(r * kernel)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RELU Activation and Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def activation_ReLU(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "\n",
        "def max_pool(X, pool_size=(2, 2), stride=2, padding=0):\n",
        "    \"\"\"\n",
        "    Perform max pooling on input feature map X with specified pool size and stride.\n",
        "\n",
        "    X: input feature map of shape (D, H, W)\n",
        "    \"\"\"\n",
        "    p_height, p_width = pool_size\n",
        "    num_filters, H, W = X.shape\n",
        "\n",
        "    outH = (H - p_height + 2 * padding) // stride + 1\n",
        "    outW = (W - p_width + 2 * padding) // stride + 1\n",
        "    output = np.zeros((num_filters, outH, outW))\n",
        "\n",
        "    for d in range(num_filters):\n",
        "        for i in range(outH):\n",
        "            for j in range(outW):\n",
        "                h1 = i * stride\n",
        "                h2 = h1 + p_height\n",
        "                w1 = j * stride\n",
        "                w2 = w1 + p_width\n",
        "                  \n",
        "                region = X[d, h1:h2, w1:w2]\n",
        "                output[d, i, j] = np.max(region)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def perform_convolutions(X, kernels):\n",
        "    \"\"\"\n",
        "    Performs n amount of convolutions on image X, returning the final feature map\n",
        "    \"\"\"\n",
        "    cache = []\n",
        "    current = X # keeping track of current conv\n",
        "\n",
        "    for filters in kernels:\n",
        "        conv = convolve(current, filters)\n",
        "        conv_activated = activation_ReLU(conv)\n",
        "        pool_out = max_pool(conv_activated)\n",
        "\n",
        "        # 4. SAVE EVERYTHING!\n",
        "        # We store a tuple: (Input to this layer, Conv Output, ReLU Output, Pool Output)\n",
        "        layer_memory = {\n",
        "            'input': current,         \n",
        "            'conv_out': conv,         \n",
        "            'relu_out': conv_activated,\n",
        "            'pool_out': pool_out       \n",
        "        }\n",
        "        cache.append(layer_memory)\n",
        "\n",
        "        current = pool_out\n",
        "\n",
        "    return current, cache\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 3: The Dense Layer and Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_layer(conv_out, w, b):\n",
        "    \"\"\"\n",
        "    Takes a flattened conv_out and returns a list of 10 values\n",
        "    \"\"\"\n",
        "    dense = conv_out.dot(w) + b\n",
        "    return dense\n",
        "\n",
        "\n",
        "def soft_max(dense_out):\n",
        "    e_x = np.exp(dense_out - np.max(dense_out))\n",
        "    return e_x  / np.sum(e_x)\n",
        "\n",
        "\n",
        "def select_max_prob(probs):\n",
        "    classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', \n",
        "           'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "    \n",
        "    p_index = np.argmax(probs)\n",
        "    prediction = classes[p_index]\n",
        "    confidence = probs[p_index] * 100\n",
        "\n",
        "    return prediction, confidence, p_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_pass(X, w, b, kernel_weights):\n",
        "    \"\"\"\n",
        "    Performs the entire forward pass operation on image X\n",
        "    \"\"\"\n",
        "    conv_output, cache = perform_convolutions(X, kernel_weights).flatten()\n",
        "    dense_out = dense_layer(conv_output, w, b)\n",
        "\n",
        "    probabilities = soft_max(dense_out)\n",
        "    prediction, conf, pred_index = select_max_prob(probabilities)\n",
        "\n",
        "    # print(f\"Prediction: {prediction} with a confidence of {conf:.2f}%\")\n",
        "    \n",
        "    return probabilities, conv_output, cache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize kernel and dense weights. Then, perform the forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initializing kernel and dense layer weights\n",
        "# THIS IS THE STATE \n",
        "kW1 = np.random.randn(16, 3, 3, 3) * np.sqrt(2 / 27)\n",
        "kW2 = np.random.randn(32, 16, 3, 3) * np.sqrt(2 / 144)\n",
        "kW3 = np.random.randn(64, 32, 3, 3) * np.sqrt(2 / 288)\n",
        "kW = [kW1, kW2, kW3]\n",
        "\n",
        "global_weights = np.random.randn(256, 10) * np.sqrt(2 / 256)\n",
        "global_biases = np.zeros(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.3293752 , 0.03040448, 0.07231495, 0.02072551, 0.01298487,\n",
              "        0.15592381, 0.01737245, 0.31310808, 0.04056755, 0.0072231 ]),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.42387124, 0.21438271,\n",
              "        0.9122524 , 1.17846605, 1.51063375, 1.71037665, 1.59136773,\n",
              "        1.48137307, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02112459, 0.10551915,\n",
              "        0.92652971, 2.05765399, 2.56308533, 0.77076319, 0.63464097,\n",
              "        0.48067697, 0.10103869, 1.90803472, 3.06290348, 3.83679603,\n",
              "        3.66280379, 0.22163763, 0.12521135, 1.16809963, 1.44175434,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01234172, 0.        , 0.67166262, 1.32160486,\n",
              "        1.72272768, 2.07495294, 0.97319802, 1.44291223, 1.35207479,\n",
              "        1.58478124, 0.91773194, 1.3865877 , 1.24307694, 1.37670088,\n",
              "        0.        , 0.        , 0.07223309, 0.37264271, 2.09561165,\n",
              "        2.34164175, 2.68738274, 2.47615542, 0.15120542, 0.23891956,\n",
              "        0.44281974, 0.54355348, 1.69693467, 1.50290321, 1.47002182,\n",
              "        1.42546584, 0.01226964, 0.        , 0.        , 0.        ,\n",
              "        2.45426575, 2.83680477, 2.51806094, 2.15841275, 0.6504627 ,\n",
              "        0.66034729, 0.71029716, 0.62413571, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.36094   , 0.06087249, 0.56434379,\n",
              "        0.47770098, 1.70280973, 1.63896314, 1.51358115, 0.78553895,\n",
              "        0.57226943, 0.35696277, 0.        , 0.        , 2.04979077,\n",
              "        1.95762065, 1.8328337 , 1.82941366, 2.35587634, 2.65381442,\n",
              "        3.20953859, 3.31319241, 0.        , 0.        , 0.        ,\n",
              "        0.        , 1.72567564, 1.64357839, 2.745514  , 2.76752856,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.90225887,\n",
              "        1.38391462, 1.85305691, 1.61271291, 0.69698242, 1.0116702 ,\n",
              "        0.68366775, 0.94741396, 0.5018078 , 0.72975036, 1.07467573,\n",
              "        0.85464062, 1.18624194, 1.63875559, 1.77503245, 2.22399864,\n",
              "        0.8790393 , 0.78052505, 0.57568691, 0.64013618, 0.63330744,\n",
              "        0.94446907, 0.47945287, 0.8356814 , 1.25116088, 1.2564528 ,\n",
              "        1.14423921, 0.99059705, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.61720411, 0.44188338, 0.45165007, 0.52789579,\n",
              "        0.52774402, 1.12561264, 2.12937346, 2.31106791, 1.60213459,\n",
              "        1.71553622, 1.53958869, 1.82238311, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.13490587, 0.        , 1.39957043,\n",
              "        1.4636089 , 0.31644484, 0.54231272, 0.65235378, 0.6997282 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03945709, 0.03796902, 0.        , 0.        ,\n",
              "        0.        , 0.        , 1.87297677, 1.82374212, 2.08847612,\n",
              "        2.26387508, 1.11936539, 1.27473089, 1.02184165, 1.16549594,\n",
              "        0.19093453, 0.25182177, 0.        , 0.26254579, 0.12566906,\n",
              "        0.29027416, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02462356, 0.50172149, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        1.678978  , 2.02176657, 1.92402749, 0.75617068, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.92395661, 1.15571763,\n",
              "        1.23005024, 1.90744533, 2.75367023, 3.04925359, 3.31642902,\n",
              "        3.37316779, 0.60813206, 0.89957424, 0.13691578, 0.27224249,\n",
              "        0.52662732, 1.4203479 , 0.92659197, 1.03665765, 0.60749999,\n",
              "        0.43548287, 0.85422926, 0.77558082, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.09808889, 0.06323671, 0.        ,\n",
              "        0.08847126]))"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forward_pass(testImg, global_weights, global_biases, kW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 4: Stochastic Gradient Descent and Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot(Y):\n",
        "    one_hot_vector = np.zeros(10)\n",
        "    one_hot_vector[Y] = 1.0\n",
        "    \n",
        "    return one_hot_vector\n",
        "\n",
        "def stoch_gradient_descent(X, Y, w, b, alpha=0.01):\n",
        "    # probs [] and flattened feature map  is returned\n",
        "    probs, conv_out, cache = forward_pass(X, global_weights, global_biases, kW) \n",
        "\n",
        "    loss = -np.log(probs[Y] + 1e-9) # small offset to avoid 0 log\n",
        "\n",
        "    new_w, new_b, d_conv3_out, p2 = backward_pass(\n",
        "        probs, Y, w, b, conv_out, cache, alpha\n",
        "    )\n",
        "\n",
        "    return new_w, new_b, loss, d_conv3_out, p2\n",
        "\n",
        "\n",
        "def backward_pass(probs, Y, w, b, conv_out, cache, alpha=0.01):\n",
        "    \"\"\"\n",
        "    Handles the backward pass from Loss -> Dense -> Conv Output.\n",
        "    \"\"\"\n",
        "    trueY = one_hot(Y)\n",
        "    dLZ = (probs - trueY)\n",
        "    \n",
        "    # derivative of loss w.r.t W\n",
        "    dzW = conv_out\n",
        "    \n",
        "    # d of loss w.r.t weights and biases\n",
        "    dLW = np.outer(dzW, dLZ)\n",
        "    dLB = dLZ\n",
        "    \n",
        "    d_flattened = w.dot(dLZ)\n",
        "    \n",
        "    # update Dense Weights & Biases\n",
        "    new_w = w - (alpha * dLW)\n",
        "    new_b = b - (alpha * dLB)\n",
        "    \n",
        "    layer3_data = cache[-1] \n",
        "    \n",
        "    p3 = layer3_data['pool_out']   \n",
        "    a3 = layer3_data['relu_out'] \n",
        "    c3 = layer3_data['conv_out']  \n",
        "    p2 = layer3_data['input']     \n",
        "    \n",
        "    # Reshape flat error back to 3D\n",
        "    d_pool3_out = d_flattened.reshape(p3.shape)\n",
        "    \n",
        "    # Backprop through Max Pool\n",
        "    d_relu3_out = reverse_max_pool(d_pool3_out, a3)\n",
        "    \n",
        "    # Backprop through ReLU\n",
        "    d_conv3_out = reverse_ReLU(d_relu3_out, c3)\n",
        "    \n",
        "    return new_w, new_b, d_conv3_out, p2\n",
        "\n",
        "def reverse_ReLU(d_out, X_input):\n",
        "    d_input = d_out.copy() \n",
        "    d_input[X_input <= 0] = 0\n",
        "\n",
        "    return d_input\n",
        "\n",
        "def reverse_max_pool(d_pool_out, x_conv, pool_size=(2, 2), stride=2):\n",
        "    (num_filters, out_h, out_w) = d_pool_out.shape\n",
        "    d_pool_in = np.zeros_like(x_conv)\n",
        "    p_h, p_w = pool_size\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the full pipeline on one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = testImg\n",
        "\n",
        "# global_weights, global_biases, loss = stoch_gradient_descent(\n",
        "#     image, \n",
        "#     labels[0], \n",
        "#     global_weights, \n",
        "#     global_biases, \n",
        "#     alpha=0.01\n",
        "# )\n",
        "\n",
        "# print(f\"Loss for this image: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 5: Training the Model on the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1----\n",
            "EPOCH 1 ACCURACY: 24.00 %\n",
            "EPOCH 2----\n",
            "EPOCH 2 ACCURACY: 31.80 %\n",
            "EPOCH 3----\n",
            "EPOCH 3 ACCURACY: 32.20 %\n",
            "EPOCH 4----\n",
            "EPOCH 4 ACCURACY: 31.80 %\n",
            "EPOCH 5----\n",
            "EPOCH 5 ACCURACY: 32.40 %\n",
            "EPOCH 6----\n",
            "EPOCH 6 ACCURACY: 31.80 %\n",
            "EPOCH 7----\n",
            "EPOCH 7 ACCURACY: 32.20 %\n",
            "EPOCH 8----\n",
            "EPOCH 8 ACCURACY: 30.20 %\n",
            "EPOCH 9----\n",
            "EPOCH 9 ACCURACY: 33.00 %\n",
            "EPOCH 10----\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[195]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, Y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_batch)):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         global_weights, global_biases, _ = \u001b[43mstoch_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mY_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglobal_biases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrate\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     batch_count += \u001b[32m1\u001b[39m\n\u001b[32m     36\u001b[39m correct = \u001b[32m0\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[191]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mstoch_gradient_descent\u001b[39m\u001b[34m(X, Y, w, b, alpha)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstoch_gradient_descent\u001b[39m(X, Y, w, b, alpha=\u001b[32m0.01\u001b[39m):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# probs [] and flattened feature map  is returned\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     probs, conv_out = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_biases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkW\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     10\u001b[39m     trueY = one_hot(Y)\n\u001b[32m     12\u001b[39m     loss = -np.log(probs[Y] + \u001b[32m1e-9\u001b[39m) \u001b[38;5;66;03m# small offset to avoid 0 log\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[188]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(X, w, b, kernel_weights)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_pass\u001b[39m(X, w, b, kernel_weights):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Performs the entire forward pass operation on image X\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     conv_output = \u001b[43mperform_convolutions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_weights\u001b[49m\u001b[43m)\u001b[49m.flatten()\n\u001b[32m      6\u001b[39m     dense_out = dense_layer(conv_output, w, b)\n\u001b[32m      8\u001b[39m     probabilities = soft_max(dense_out)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[186]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mperform_convolutions\u001b[39m\u001b[34m(X, kernels)\u001b[39m\n\u001b[32m     36\u001b[39m current = X \u001b[38;5;66;03m# keeping track of current conv\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filters \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     conv = \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     conv_activated = activation_ReLU(conv)\n\u001b[32m     41\u001b[39m     current = max_pool(conv_activated)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[185]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mconvolve\u001b[39m\u001b[34m(X, filters, padding, stride)\u001b[39m\n\u001b[32m     37\u001b[39m             \u001b[38;5;66;03m# perform convolution of the kernel and image region\u001b[39;00m\n\u001b[32m     38\u001b[39m             r = X[:, h1:h2, w1:w2]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m             output[d, i, j] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2333\u001b[39m, in \u001b[36m_sum_dispatcher\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing `min` or `max` keyword argument when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2328\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m'\u001b[39m, a_min, a_max, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2334\u001b[39m                     initial=\u001b[38;5;28;01mNone\u001b[39;00m, where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[32m   2338\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[32m   2339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue,\n\u001b[32m   2340\u001b[39m         initial=np._NoValue, where=np._NoValue):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "epoch = 20\n",
        "batch_size = 64\n",
        "rate = 0.005 # learning rate\n",
        "loss = [] # will be used to plot loss overtime\n",
        "per_batch = 5\n",
        "\n",
        "# X_train = X_train / 255.0\n",
        "# X_test = X_test / 255.0\n",
        "# X_val = X_val / 255.0\n",
        "\n",
        "# small set for testing\n",
        "small_X = X_train[:1000]\n",
        "small_Y = Y_train[:1000]\n",
        "\n",
        "small_X_val = X_val[:500]\n",
        "small_Y_val = Y_val[:500]\n",
        "\n",
        "for e_num in range(epoch):\n",
        "    print(f\"EPOCH {e_num+1}----\")\n",
        "    batches = batch_generator(small_X, small_Y, batch_size)\n",
        "    batch_count = 0\n",
        "\n",
        "    for X_batch, Y_batch in batches:\n",
        "        for i in range(len(X_batch)):\n",
        "            global_weights, global_biases, _, _ = stoch_gradient_descent(\n",
        "                X_batch[i], \n",
        "                Y_batch[i], \n",
        "                global_weights, \n",
        "                global_biases, \n",
        "                alpha=rate\n",
        "            )\n",
        "        \n",
        "        batch_count += 1\n",
        "    \n",
        "    correct = 0\n",
        "    total_val = len(small_X_val) \n",
        "    \n",
        "    for k in range(len(small_X_val)):\n",
        "        probs, _ = forward_pass(small_X_val[k], global_weights, global_biases, kW)\n",
        "        if np.argmax(probs) == small_Y_val[k]:\n",
        "            correct += 1\n",
        "            \n",
        "    final_acc = (correct / total_val) * 100\n",
        "    print(f\"EPOCH {e_num+1} ACCURACY: {final_acc:.2f} %\")\n",
        "    if final_acc > 20:\n",
        "        rate = 0.0001  # Slow down 10x to take tiny, careful steps\n",
        "    time.sleep(5)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Citation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CIFAR-10 dataset generously provided by __Alex Krizhevskyâ€™s 2009 technical report, Learning Multiple Layers of Features from Tiny Images__"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
